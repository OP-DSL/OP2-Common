{# Template imports #}
{% from 'cpp/macros.j2' import op_opt, op_host_stub_args, op_host_set_mappings, op_host_vec_arg_arrays %}
{% from 'macros.j2' import comma %}
// user function
#include "../{{ parloop.kernelPath }}"

// host stub function
void op_par_loop_{{ parloop.name }}(
  char const *name,
  op_set set,
  {% for arg in parloop.unique %}
  op_arg arg{{ arg.i }}{{ comma(loop) }}
  {% endfor %}
) {

  {{ op_host_stub_args(parloop) }}

  // initialise timers
  double cpu_t1, cpu_t2, wall_t1, wall_t2;
  op_timing_realloc({{ id }});
  op_timers_core(&cpu_t1, &wall_t1);

  if (OP_diags>2) {
    printf(" kernel routine {{ 'with' if parloop.indirection else 'w/o' }} indirection: {{ parloop.name }}\n");
  }

  {% if opt.config['grouped'] %}
  int set_size = op_mpi_halo_exchanges_grouped(set, nargs, args, 1);
  {% else %}
  int set_size = op_mpi_halo_exchanges(set, nargs, args);
  {% endif %}

  if(set_size > 0) {
    {% if parloop.indirection %}
    {#
    #### Kernel call for indirect version ####
    #}
    for(int n = 0; n < set_size; n++) {
      if(n < set->core_size && n > 0 && n % OP_mpi_test_frequency == 0)
        op_mpi_test_all(nargs, args);

      if(n == set->core_size)
        {% if opt.config['grouped'] %}
        op_mpi_wait_all_grouped(nargs, args, 1);
        {% else %}
        op_mpi_wait_all(nargs, args);
        {% endif %}

      {# Declare and set mappings #}
      {% filter indent(width=6) %}
      {{ op_host_set_mappings(parloop) }}
      {% endfilter %}

      {# Create vec arguments #}
      {% filter indent(width=6) %}
      {{ op_host_vec_arg_arrays(parloop) }}
      {% endfilter %}

      {# Actual kernel call #}
      {{ parloop.name }}(
        {% for arg in parloop.unique %}
        {% if arg.direct %}
        &(({{ arg.typ }}*)arg{{ arg.datInd }}.data)[{{ arg.dim }} * n]{{ comma(loop) }}
        {% elif arg.indirect %}
        {% if arg.vec %}
        arg{{ arg.i }}_vec{{ comma(loop) }}
        {% elif not arg.vec %}
        &(({{ arg.typ }}*)arg{{ arg.datInd }}.data)[{{ arg.dim }} * map{{ arg.mapIdxInd }}idx]{{ comma(loop) }}
        {% endif %}
        {% elif arg.global_ %}
        ({{ arg.typ }}*)arg{{ arg.i }}.data{{ comma(loop) }}
        {% endif %}
        {% endfor %}
      );
    }
    {% else %}
    {#
    #### Kernel call for direct version ####
    #}
    for(int n = 0; n < set_size; n++) {
      {# Actual kernel call #}
      {{ parloop.name }}(
        {% for arg in parloop.unique %}
        {% if arg.direct %}
        &(({{ arg.typ }}*)arg{{ arg.datInd }}.data)[{{ arg.dim }} * n]{{ comma(loop) }}
        {% elif arg.global_ %}
        ({{ arg.typ }}*)arg{{ arg.i }}.data{{ comma(loop) }}
        {% endif %}
        {% endfor %}
      );
    }
    {% endif %}
  }

  {# Account for a zero set size #}
  {% if parloop.indirection %}
  if(set_size == 0 || set_size == set->core_size)
    op_mpi_wait_all(nargs, args);
  {% endif %}

  // Combine reduction data
  {% for arg in parloop.globals %}
  {% if arg.acc != "OP_READ" %}
  {% if arg.typ == "double" %}
  op_mpi_reduce_double(&arg{{ arg.i }},({{ arg.typ }}*)arg{{ arg.i }}.data);
  {% elif arg.typ == "float" %}
  op_mpi_reduce_float(&arg{{ arg.i }},({{ arg.typ }}*)arg{{ arg.i }}.data);
  {% elif arg.typ == "int" %}
  op_mpi_reduce_int(&arg{{ arg.i }},({{ arg.typ }}*)arg{{ arg.i }}.data);
  {% else %}
  {{ parloop.raise_exception("Type of global is not supported in OpenACC code generator, please add it") }}
  {% endif %}
  {% endif %}
  {% endfor %}
  op_mpi_set_dirtybit(nargs, args);

  // Update kernel record
  op_timers_core(&cpu_t2, &wall_t2);
  OP_kernels[{{ id }}].name   = name;
  OP_kernels[{{ id }}].count += 1;
  OP_kernels[{{ id }}].time  += wall_t2 - wall_t1;

  {% if parloop.indirection %}
  {% for arg in parloop.unique %}
  {%- call op_opt(arg) %}
  OP_kernels[{{ id }}].transfer += (float)set->size * arg{{ arg.i }}.size{{ '' if arg.acc == "OP_READ" or arg.acc == "OP_WRITE" else ' * 2.0f' }};
  {% endcall %}
  {% endfor %}
  {% if parloop.nmaps > 0 %}
  {% for arg in parloop.expanded_args %}
  {% if arg.indirect and arg.mapInd == arg.i %}
  OP_kernels[{{ id }}].transfer += (float)set->size * arg{{ arg.mapInd }}.map->dim * 4.0f;
  {% endif %}
  {% endfor %}
  {% endif %}
  {% else %}
  {% for arg in parloop.unique %}
  {% if not arg.global_ %}
  {%- call op_opt(arg) %}
  OP_kernels[{{ id }}].transfer += (float)set->size * arg{{ arg.i }}.size{{ '' if arg.acc == "OP_READ" else ' * 2.0f' }};
  {% endcall %}
  {% endif %}
  {% endfor %}
  {% endif %}
}

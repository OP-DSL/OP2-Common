{% extends "cpp/loop_host.hpp.jinja" %}

{%- macro arg_to_pointer(arg) -%}
    {%- if arg is gbl -%}
gbl{{arg.id}}
    {%- elif arg is direct -%}
dat{{arg.dat_id}} + n * {{lh.dat(arg).dim}}
    {%- else -%}
dat{{arg.dat_id}} + map{{arg.map_id}}[n * map{{arg.map_id}}_dim + {{arg.map_idx}}] * {{lh.dat(arg).dim}}
    {%- endif -%}
{%- endmacro -%}

{%- macro arg_local(arg) -%}
arg{{arg.id}}{{"_%s" % (arg.map_idx) if arg is indirect}}_local
{%- endmacro -%}

{%- macro arg_to_pointer_local(arg) -%}
    {%- if arg is read -%}
{{arg_to_pointer(arg)}}
    {%- else -%}
{{arg_local(arg)}}[lane]
    {%- endif -%}
{%- endmacro -%}

{% set vectorise = target.config.vectorise.enable and lh.kernel not in target.config.vectorise.blacklist %}

{% block host_prologue %}
    {% if vectorise %}
#define SIMD_LEN {{target.config.vectorise.simd_len}}
    {% endif %}

void {{lh.kernel}}_wrapper(
    {% for dat in lh.dats %}
    {{"const " if dat is read_in(lh)}}{{dat.typ}} *__restrict__ dat{{dat.id}}_u,
    {% endfor %}
    {% for map in lh.maps %}
    const int *__restrict__ map{{map.id}}_u,
    int map{{map.id}}_dim,
    {% endfor %}
    {% for arg in lh.args|gbl %}
    {{"const " if arg is read}}{{arg.typ}} *__restrict__ gbl{{arg.id}},
    {% endfor %}
    int start,
    int end
) {
    {% for dat in lh.dats %}
    {{"const " if dat is read_in(lh)}}{{dat.typ}} *__restrict__ dat{{dat.id}} = assume_aligned(dat{{dat.id}}_u);
    {% endfor %}
    {% for map in lh.maps %}
    const int *__restrict__ map{{map.id}} = assume_aligned(map{{map.id}}_u);
    {% endfor %}

    {% if vectorise %}
    int block = start;
    for (; block + SIMD_LEN < end; block += SIMD_LEN) {
        {% for arg in lh.args_expanded|dat if arg is not read %}
        alignas(SIMD_LEN * 8) {{lh.dat(arg).typ}} {{arg_local(arg)-}}
            [SIMD_LEN][{{lh.dat(arg).dim}}]{{-" = {0}" if arg is inc}};
        {% endfor %}
        {% for arg in lh.args|gbl|reduction %}
        alignas(SIMD_LEN * 8) {{arg.typ}} {{arg_local(arg)}}[SIMD_LEN][{{arg.dim}}]{{" = {0}" if arg is inc}};
        {% endfor %}

        for (int lane = 0; lane < SIMD_LEN; ++lane) {
            int n = block + lane;

            {% for arg in lh.args_expanded|dat|read_write %}
            for (int d = 0; d < {{lh.dat(arg).dim}}; ++d) {
                {{arg_to_pointer_local(arg)}}[d] = ({{arg_to_pointer(arg)}})[d];
            }{{"\n" if not loop.last}}
            {% endfor %}
            {% for arg in lh.args|gbl|reduction if arg is not inc %}
            for (int d = 0; d < {{arg.dim}}; ++d) {
                {{arg_to_pointer_local(arg)}}[d] = ({{arg_to_pointer(arg)}})[d];
            }{{"\n" if not loop.last}}
            {% endfor %}
        }

        #pragma omp simd
        for (int lane = 0; lane < SIMD_LEN; ++lane) {
            int n = block + lane;

        {% for arg in lh.args|vec %}
            {{"const " if arg is read}}{{lh.dat(arg).typ}} *arg{{arg.id}}_vec[] = {
            {% for arg_expanded in lh.args_expanded if arg_expanded.id == arg.id %}
                {{arg_to_pointer_local(arg_expanded)}}{{"," if not loop.last}}
            {% endfor %}
            };

        {% endfor %}
            op2_k{{kernel_idx}}::{{lh.kernel}}(
        {% for arg in lh.args %}
            {% if arg is not vec %}
                {{arg_to_pointer_local(arg)}}
            {%- else %}
                arg{{arg.id}}_vec
            {%- endif %}{{"," if not loop.last}}
        {% endfor %}
            );
        }

        for (int lane = 0; lane < SIMD_LEN; ++lane) {
            int n = block + lane;
        {% for arg in lh.args_expanded|dat if arg is not read %}

            for (int d = 0; d < {{lh.dat(arg).dim}}; ++d) {
                ({{arg_to_pointer(arg)}})[d] {{"+" if arg is inc-}}= {{arg_to_pointer_local(arg)}}[d];
            }
        {% endfor %}
        {% for arg in lh.args|gbl|reduction %}

            for (int d = 0; d < {{arg.dim}}; ++d) {
            {% if arg is inc %}
                {{arg_to_pointer(arg)}}[d] += {{arg_to_pointer_local(arg)}}[d];
            {% else %}
                {{arg_to_pointer(arg)}}[d] = {{arg.access_type.name-}}
                    ({{arg_to_pointer(arg)}}[d], {{arg_to_pointer_local(arg)}}[d]);
            {% endif %}
            }
        {% endfor %}
        }
    }

    {% endif %}
    for (int n = {{"block" if vectorise else "start"}}; n < end; ++n) {
        {% for arg in lh.args|vec %}
        {{"const " if arg.access_type == OP.AccessType.READ}}{{lh.dat(arg).typ}} *arg{{arg.id}}_vec[] = {
            {% for arg_expanded in lh.args_expanded if arg_expanded.id == arg.id %}
            {{arg_to_pointer(arg_expanded)}}{{"," if not loop.last}}
            {% endfor %}
        };

        {% endfor %}
        op2_k{{kernel_idx}}::{{lh.kernel}}(
        {% for arg in lh.args %}
            {% if arg is not vec %}
            {{arg_to_pointer(arg)}}
            {%- else %}
            arg{{arg.id}}_vec
            {%- endif %}{{"," if not loop.last}}
        {% endfor %}
        );
    }
}

{{super()}}
    {% if lh is indirect %}
    {{indirect_dat_descriptor_def()|indent}}

#ifdef OP_PART_SIZE_{{kernel_idx}}
    int part_size = OP_PART_SIZE_{{kernel_idx}};
#else
    int part_size = OP_part_size;
#endif

    op_plan *plan = op_plan_get_stage_upload(name, set, part_size, num_args_expanded, args_expanded,
        num_dats_indirect, dats_indirect, OP_STAGE_ALL, 0);
    {% endif %}
    {% if lh is direct or lh.args|gbl|reduction|length > 0 %}

#ifdef _OPENMP
    int num_threads = omp_get_max_threads();
#else
    int num_threads = 1;
#endif
    {% endif %}
    {% for arg in lh.args|gbl|reduction %}

    {{arg.typ}} *gbl{{arg.id}} = ({{arg.typ}} *)arg{{arg.id}}.data;
    {{arg.typ}} gbl{{arg.id}}_local[num_threads * 64];

    for (int thread = 0; thread < num_threads; ++thread) {
        for (int d = 0; d < {{arg.dim}}; ++d)
            gbl{{arg.id}}_local[thread * 64 + d] = {% if arg is inc -%}
                ZERO_{{arg.typ}}
            {%- else -%}
                gbl{{arg.id}}[d]
            {%- endif %};
    }
    {% endfor %}
{% endblock %}

{% block host_prologue_early_exit_cleanup %}
    {% if lh is indirect %}
        op_mpi_wait_all(num_args_expanded, args_expanded);

    {% endif %}
    {% for arg in lh.args|gbl|reduction %}
        op_mpi_reduce(&arg{{arg.id}}, ({{arg.typ}} *)arg{{arg.id}}.data);
    {% endfor %}
        op_mpi_set_dirtybit(num_args_expanded, args_expanded);
{% endblock %}

{% block host_loop %}
    {% if lh is direct %}
    #pragma omp parallel for
    for (int thread = 0; thread < num_threads; ++thread) {
        int start = (set->size * thread) / num_threads;
        int end = (set->size * (thread + 1)) / num_threads;

        {{lh.kernel}}_wrapper(
        {% for dat in lh.dats %}
            ({{dat.typ}} *)arg{{dat.arg_id}}.data,
        {% endfor %}
        {% for arg in lh.args|gbl %}
            {% if arg is reduction %}
            gbl{{arg.id}}_local + 64 * omp_get_thread_num(),
            {% else %}
            ({{arg.typ}} *)arg{{arg.id}}.data,
            {% endif %}
        {% endfor %}
            start,
            end
        );
    }
    {% else %}
    int block_offset = 0;
    for (int col = 0; col < plan->ncolors; ++col) {
        if (col == plan->ncolors_core)
            op_mpi_wait_all(num_args_expanded, args_expanded);

        int num_blocks = plan->ncolblk[col];

        #pragma omp parallel for
        for (int block_idx = 0; block_idx < num_blocks; ++block_idx) {
            int block_id = plan->blkmap[block_idx + block_offset];
            int num_elem = plan->nelems[block_id];
            int offset = plan->offset[block_id];

            {{lh.kernel}}_wrapper(
        {% for dat in lh.dats %}
                ({{dat.typ}} *)arg{{dat.arg_id}}.data,
        {% endfor %}
        {% for map in lh.maps %}
                arg{{map.arg_id}}.map_data,
                arg{{map.arg_id}}.map->dim,
        {% endfor %}
        {% for arg in lh.args|gbl %}
            {% if arg is reduction %}
                gbl{{arg.id}}_local + 64 * omp_get_thread_num(),
            {% else %}
                ({{arg.typ}} *)arg{{arg.id}}.data,
            {% endif %}
        {% endfor %}
                offset,
                offset + num_elem
            );
        }

        block_offset += num_blocks;
        {% if direct or lh.args|gbl|reduction|length > 0 %}

        if (col != plan->ncolors_owned - 1)
            continue;

            {% for arg in lh.args|gbl|reduction %}
        for (int thread = 0; thread < num_threads; ++thread) {
            for (int d = 0; d < {{arg.dim}}; ++d)
                {% if arg is inc %}
                gbl{{arg.id}}[d] += gbl{{arg.id}}_local[thread * 64 + d];
                {% else %}
                gbl{{arg.id}}[d] = {{arg.access_type.name-}}
                    (gbl{{arg.id}}[d], gbl{{arg.id}}_local[thread * 64 + d]);
                {% endif %}
        }
            {% endfor %}
        {% endif  %}
    }
    {% endif %}
{% endblock %}

{% block host_epilogue %}
    {% if lh is indirect -%} {# TODO: is this indirect check necessary? #}
    if (set_size == set->core_size)
        op_mpi_wait_all(num_args_expanded, args_expanded);

    {% endif %}
    {% if lh is direct %}
        {% for arg in lh.args|gbl|reduction %}
    for (int thread = 0; thread < num_threads; ++thread) {
        for (int d = 0; d < {{arg.dim}}; ++d)
            {% if arg is inc %}
            gbl{{arg.id}}[d] += gbl{{arg.id}}_local[thread * 64 + d];
            {% else %}
            gbl{{arg.id}}[d] = {{arg.access_type.name-}}
                (gbl{{arg.id}}[d], gbl{{arg.id}}_local[thread * 64 + d]);
            {% endif %}
    }
            {% endfor %}

    {% endif %}
    {% for arg in lh.args|gbl|reduction %}
    op_mpi_reduce(&arg{{arg.id}}, gbl{{arg.id}});
    {% endfor %}
    op_mpi_set_dirtybit(num_args_expanded, args_expanded);

{{super()}}
{% endblock %}

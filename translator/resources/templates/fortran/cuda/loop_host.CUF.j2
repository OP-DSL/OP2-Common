
{# !!! WIP !!! #}

{# Template imports #}
{% from 'fortran/macros.j2' import op_opt %}
{% from 'macros.j2' import comma %}

{% set atomics = opt.config['atomics'] %}

MODULE {{ parloop.name | upper }}_MODULE

  USE OP2_CONSTANTS
  USE OP2_FORTRAN_DECLARATIONS
  USE OP2_FORTRAN_RT_SUPPORT
  USE ISO_C_BINDING
  USE CUDAFOR
  USE CUDACONFIGURATIONPARAMS

#ifdef _OPENMP
    USE OMP_LIB
#endif

  ! {{ parloop.kernel }} variable declarations

  {# TODO: Strides for SoA #}

  {% for arg in parloop.globals %}
  {% if arg.acc == 'OP_READ' %}
  {{ arg.typ }}, DIMENSION(:), DEVICE, ALLOCATABLE :: gblDat_{{ arg.var }}
  {% else %}
  {{ arg.typ }}, DIMENSION(:), DEVICE, ALLOCATABLE :: reductionArrayDevice{{ arg.i+1 }}update
  {% endif %}
  {% endfor %}

  {% if parloop.indirection %}
  TYPE ( c_ptr )  :: planReturn
  {% endif %}

  {# {% if TODO: anySoa %}
#define OP2_SOA(var,dim,stride) var((dim-1)*stride+1)
  {% endif %} #}

  CONTAINS
  {#  #}
  {% if parloop.reduction %}
  ! Standard cuda kernel reduction
  attributes (device) SUBROUTINE ReductionFloat8(sharedDouble8, reductionResult,inputValue,reductionOperation)
    REAL(kind=8), DIMENSION(:), DEVICE :: reductionResult
    REAL(kind=8) :: inputValue
    INTEGER(kind=4), VALUE :: reductionOperation
    REAL(kind=8), DIMENSION(0:*) :: sharedDouble8
    INTEGER(kind=4) :: i1
    INTEGER(kind=4) :: threadID
    threadID = threadIdx%x - 1
    i1 = ishft(blockDim%x,-1)
    CALL syncthreads()
    sharedDouble8(threadID) = inputValue

    DO WHILE (i1 > 0)
      CALL syncthreads()
      IF (threadID < i1) THEN
        SELECT CASE(reductionOperation)
          CASE (0)
            sharedDouble8(threadID) = sharedDouble8(threadID) + sharedDouble8(threadID + i1)
          CASE (1)
            IF (sharedDouble8(threadID + i1) < sharedDouble8(threadID)) THEN
              sharedDouble8(threadID) = sharedDouble8(threadID + i1)
            END IF
          CASE (2)
            IF (sharedDouble8(threadID + i1) > sharedDouble8(threadID)) THEN
              sharedDouble8(threadID) = sharedDouble8(threadID + i1)
            END IF
        END SELECT
      END IF
      i1 = ishft(i1,-1)
    END DO

    CALL syncthreads()

    IF (threadID .EQ. 0) THEN
      SELECT CASE(reductionOperation)
        CASE (0)
          reductionResult(1) = reductionResult(1) + sharedDouble8(0)
        CASE (1)
          IF (sharedDouble8(0) < reductionResult(1)) THEN
            reductionResult(1) = sharedDouble8(0)
          END IF
        CASE (2)
          IF (sharedDouble8(0) > reductionResult(1)) THEN
            reductionResult(1) = sharedDouble8(0)
          END IF
      END SELECT
    END IF

    CALL syncthreads()
  END SUBROUTINE

  ! Standard cuda kernel reduction
  attributes (device) SUBROUTINE ReductionInt4(sharedInt4, reductionResult,inputValue,reductionOperation)
    INTEGER(kind=4), DIMENSION(:), DEVICE :: reductionResult
    INTEGER(kind=4) :: inputValue
    INTEGER(kind=4), VALUE :: reductionOperation
    INTEGER(kind=4), DIMENSION(0:*) :: sharedInt4
    INTEGER(kind=4) :: i1
    INTEGER(kind=4) :: threadID
    threadID = threadIdx%x - 1
    i1 = ishft(blockDim%x,-1)
    CALL syncthreads()
    sharedInt4(threadID) = inputValue

    DO WHILE (i1 > 0)
      CALL syncthreads()
      IF (threadID < i1) THEN
        SELECT CASE(reductionOperation)
          CASE (0)
            sharedInt4(threadID) = sharedInt4(threadID) + sharedInt4(threadID + i1)
          CASE (1)
            IF (sharedInt4(threadID + i1) < sharedInt4(threadID)) THEN
              sharedInt4(threadID) = sharedInt4(threadID + i1)
            END IF
          CASE (2)
            IF (sharedInt4(threadID + i1) > sharedInt4(threadID)) THEN
              sharedInt4(threadID) = sharedInt4(threadID + i1)
            END IF
        END SELECT
      END IF
      i1 = ishft(i1,-1)
    END DO

    CALL syncthreads()

    IF (threadID .EQ. 0) THEN
      SELECT CASE(reductionOperation)
        CASE (0)
          reductionResult(1) = reductionResult(1) + sharedInt4(0)
        CASE (1)
          IF (sharedInt4(0) < reductionResult(1)) THEN
            reductionResult(1) = sharedInt4(0)
          END IF
        CASE (2)
          IF (sharedInt4(0) > reductionResult(1)) THEN
            reductionResult(1) = sharedInt4(0)
          END IF
      END SELECT
    END IF

    CALL syncthreads()
  END SUBROUTINE
  {% endif %}

  {% if parloop.multiDimReduction %}
  ! Multidimensional cuda kernel reduction
  attributes (device) SUBROUTINE ReductionFloat8Mdim(sharedDouble8, reductionResult,inputValue,reductionOperation,dim)
    REAL(kind=8), DIMENSION(:), DEVICE :: reductionResult
    REAL(kind=8), DIMENSION(:) :: inputValue
    INTEGER(kind=4), VALUE :: reductionOperation
    INTEGER(kind=4), VALUE :: dim
    REAL(kind=8), DIMENSION(0:*) :: sharedDouble8
    INTEGER(kind=4) :: i1
    INTEGER(kind=4) :: d
    INTEGER(kind=4) :: threadID
    threadID = threadIdx%x - 1
    i1 = ishft(blockDim%x,-1)
    CALL syncthreads()
    sharedDouble8(threadID*dim:threadID*dim+dim-1) = inputValue(1:dim)

    DO WHILE (i1 > 0)
      CALL syncthreads()
      IF (threadID < i1) THEN
        SELECT CASE(reductionOperation)
          CASE (0)
            DO i2 = 0, dim - 1, 1
              sharedDouble8(threadID*dim + i2) = sharedDouble8(threadID*dim + i2) + sharedDouble8((threadID + i1)*dim + i2)
            END DO
          CASE (1)
            DO i2 = 0, dim - 1, 1
              sharedDouble8(threadID*dim + i2) = MIN(sharedDouble8(threadID*dim + i2), sharedDouble8((threadID + i1)*dim + i2))
            END DO
          CASE (2)
            DO i2 = 0, dim - 1, 1
              sharedDouble8(threadID*dim + i2) = MAX(sharedDouble8(threadID*dim + i2), sharedDouble8((threadID + i1)*dim + i2))
            END DO
        END SELECT
      END IF
      i1 = ishft(i1,-1)
    END DO

    CALL syncthreads()

    IF (threadID .EQ. 0) THEN
      SELECT CASE(reductionOperation)
        CASE (0)
          reductionResult(1:dim) = reductionResult(1:dim) + sharedDouble8(0:dim-1)
        CASE (1)
          DO i2 = 0, dim - 1, 1
            reductionResult(1+i2) = MIN(reductionResult(1+i2) , sharedDouble8(i2))
          END DO
        CASE (2)
          DO i2 = 0, dim - 1, 1
            reductionResult(1+i2) = MAX(reductionResult(1+i2) , sharedDouble8(i2))
          END DO
      END SELECT
    END IF

    CALL syncthreads()
  END SUBROUTINE
  {% endif %}

  attributes (host) &
#include "{{ parloop.kernel }}.inc"
  attributes (device) &
#include "{{ parloop.kernel }}_cuda.inc"

  ! CUDA kernel wrapper function
  attributes (global) SUBROUTINE {{ parloop.name }}_cuda_wrap( &
    {# TODO: OPT flags #}
    {# Globals #}
    {% for arg in parloop.globals %}
    {# & gblDat_{{ arg.var }}, & #}
    {% endfor %}
    {# Directs #}
    {% for arg in parloop.directs %}
    & dirDat_{{ arg.var }}, &
    {% endfor %}
    {# Indirects #}
    {% for arg in parloop.indirectVars %}
    & indDat_{{ arg.var }}, &
    {% endfor %}
    {# Maps #}
    {% for arg in parloop.indirectMaps %}
    & map_{{ arg.map }}, &
    {% endfor %}
    {#  #}
    {% if parloop.indirection %}
    & start, &
    & end, &
    {% if not atomics %}
    & pcol_reord, &
    {% endif %}
    {% endif %}
    & setSize &
  & )

    IMPLICIT NONE

    ! Local variables
    {# {% if TODO: nopts %}
    INTEGER(kind=4), VALUE :: optflags
    {% endif %} #}

    {# TODO: ... #}

    {# Globals #}
    {% for arg in parloop.globals %}
    {% if arg.acc == 'OP_READ' and arg.dim == 1 %}
    {{ arg.typ }}, VALUE :: gblDat_{{ arg.var }}
    {% else %}
    {{ arg.typ }}, DIMENSION(0:{{ arg.dim }}-1) :: gblDat_{{ arg.var }}
    {% endif %}
    {% endfor %}
    {# Directs #}
    {% for arg in parloop.directs %}
    {% if arg.acc == 'OP_READ' %}
    {{ arg.typ }}, DEVICE, INTENT(IN) :: dirDat_{{ arg.var }}(*)
    {% else %}
    {{ arg.typ }}, DEVICE :: dirDat_{{ arg.var }}(*)
    {% endif %}
    {% endfor %}
    {# Indirects #}
    {% for arg in parloop.indirectVars %}
    {{ arg.typ }}, DEVICE :: indDat_{{ arg.var }}(*)
    {% endfor %}
    {# Maps #}
    {% for arg in parloop.indirectMaps %}
    INTEGER(kind=4), DEVICE, INTENT(IN) :: map_{{ arg.map }}(*)
    {% endfor %}
    {# Idxs #}
    {% for arg in parloop.indirectIdxs %} 
    INTEGER(kind=4) mapIdx_{{ arg.map }}_{{ arg.idx-1 }}
    {%- endfor %}


    INTEGER(kind=4), VALUE :: setSize
    {% if parloop.indirection %}
    INTEGER(kind=4), VALUE :: start, end
    {% if not atomics %}
    INTEGER(kind=4), DIMENSION(0:*), DEVICE :: pcol_reord
    {% endif %}
    INTEGER(kind=4) :: i3
    {% endif %}
    INTEGER(kind=4) :: i2
    INTEGER(kind=4) :: i1
    {% if unknown_reduction_size %}
    INTEGER(kind=4) :: thrIdx
    {% endif %}

    {% if parloop.reduction %}
    REAL(kind=8), DIMENSION(0:*), SHARED :: redFloat8
    INTEGER(kind=4), DIMENSION(0:*), SHARED :: redInt4
    {% endif %}

    {% for arg in parloop.args %}
    {# TODO: ... #}
    {# {% if arg. %}
    {{ arg.typ }}, DIMENSION({{ arg.dim }}) :: opDat{{ arg.i+1 }}Staged
    {% endif %} #}
    {% endfor %}

    {% if unknown_reduction_size %}
    thrIdx = threadIdx%x - 1 + (blockIdx%x - 1) * blockDim%x
    {% endif %}

    {% for arg in parloop.globals %}
    {% if arg.acc == 'OP_INC' %}
    {# TODO: Needs dim #}
    gblDat_{{ arg.var }} = 0
    {% elif arg.acc in ('OP_MIN', 'OP_MAX') %}
    {# TODO: Needs dim #}
    {% if arg.dim == 1 %}
    gblDat_{{ arg.var }} = reductionArrayDevice{{ arg.i+1 }}(blockIdx%x - 1 + 1)
    {% else %}
    gblDat_{{ arg.var }} = reductionArrayDevice{{ arg.i+1 }}((blockIdx%x - 1)*({{ arg.dim }}) + 1:(blockIdx%x - 1)*({{ arg.dim }}) + ({{ arg.dim }}))
    {% endif %}
    {% endif %}
    {% endfor %}

    {% if parloop.indirection %}
    {# Indirection #}
    i1 = threadIdx%x - 1 + (blockIdx%x - 1) * blockDim%x
    IF (i1+start < end) THEN
      i3 = {{ 'i1+start' if atomics else 'pcol_reord(i1+start)' }}

      {%- for arg in parloop.indirectIdxs %} 
      mapIdx_{{ arg.map }}_{{ arg.idx-1 }} = map_{{ arg.map }}(1 + i3 + setSize * {{ arg.idx-1 }})
      {%- endfor %}

      {# TODO: opts #}
      {# {%- for arg in parloop.indirectIdxs %} 
      mapIdx_{{ arg.map }}_{{ arg.idx-1 }} = map_{{ arg.map }}(1 + i3 + setSize * {{ arg.idx-1 }})+1
      {%- endfor %} #}
      {# {%- for arg in parloop.args %} 
      TODO: stage flags
      {%- endfor %} #}

      ! kernel call
      CALL {{ parloop.kernel }}_gpu( &
      {% for arg in parloop.args %}
        {% if arg.global %}
        {# Globals #}
        & gblDat_{{ arg.var }}{% if arg.dim == 1 and arg.acc == 'OP_WRITE' %}(1){% endif %}{{ comma(loop) }} &
        {% elif arg.direct %}
        {# Directs #}
        {% if arg.dim == 1 %}
        & dirDat_{{ arg.var }}(i3 + 1){{ comma(loop) }} &
        {% else %}
        & dirDat_{{ arg.var }}(i3 * ({{ arg.dim }}) + 1: i3 * ({{ arg.dim }}) + {{ arg.dim }}){{ comma(loop) }} &
        {% endif %}
        {% elif arg.indirect %}
        {# Indirects #}
        {% if arg.dim == 1 %}
        & indDat_{{ arg.var }}(1 +  mapIdx_{{ arg.map }}_{{ arg.idx-1 }}){{ comma(loop) }} &
        {% else %}
        & indDat_{{ arg.var }}(1 +  mapIdx_{{ arg.map }}_{{ arg.idx-1 }} * ({{ arg.dim }}): mapIdx_{{ arg.map }}_{{ arg.idx-1 }} * ({{ arg.dim }}) + {{ arg.dim }}){{ comma(loop) }} &
        {% endif %}
        {% endif %}
      {% endfor %}
      & )

      {# TODO: Stage flags #}
    END IF
    {% else %}
    {# No indirection #}
    DO i1 = threadIdx%x - 1 + (blockIdx%x - 1) * blockDim%x, setSize - 1, blockDim%x * gridDim%x

      ! kernel call
      CALL {{ parloop.kernel }}_gpu( &
      {% for arg in parloop.args %}
        {% if arg.global_ %}
        {# Globals #}
        & gblDat_{{ arg.var }}{% if arg.dim == 1 and arg.acc == 'OP_WRITE' %}(1){% endif %}{{ comma(loop) }} &
        {% elif arg.direct %}
        {# Directs #}
        {% if arg.dim == 1 %}
        & dirDat_{{ arg.var }}(i1 + 1){{ comma(loop) }} &
        {% else %}
        & dirDat_{{ arg.var }}(i1 * ({{ arg.dim }}) + 1: i1 * ({{ arg.dim }}) + {{ arg.dim }}){{ comma(loop) }} &
        {% endif %}
        {% endif %}
      {% endfor %}
      & )

      {# TODO: Stage flags #}
    END DO
    {% endif %}

    {# call cuda reduction for each OP_GBL #}
    {% for arg in parloop.globals %}
    {% if arg.acc != 'OP_READ' %}
    {#  #}
    {% if arg.typ == OP.Int(True, 32) %}
    {% set type = 'Int4' %}
    {% elif arg.typ == OP.Float(64) %}
    {% set type = 'Float8' %}
    {% endif %}
    {#  #}
    {% if arg.acc == 'OP_INC' %}
    {% set access = 0 %}
    {% elif arg.acc == 'OP_MIN' %}
    {% set access = 1 %}
    {% elif arg.acc == 'OP_MAX' %}
    {% set access = 2 %}
    {% endif %}
    {#  #}
    DO i1=0, {{ arg.dim }}-1, 8
      i2 = MIN(i1+8, {{ arg.dim }})
      CALL Reduction{{ type }}Mdim(red{{ type }}, reductionArrayDevice{{ arg.i+1 }}update((blockIdx%x - 1)*({{ arg.dim }}) + 1+i1:),gblDat_{{ arg.var }}(i1:),{{ access }},i2-i1)
    END DO
    {% endif %}
    {% endfor %}
  END SUBROUTINE

  attributes (host) SUBROUTINE op_par_loop_{{ parloop.name }}_host( &
    & kernel, &
    & set, &
    {% for arg in parloop.args %}
    & opArg{{ arg.i+1 }}{{ comma(loop) }} &            
    {% endfor %}
  & )

    IMPLICIT NONE
    character(kind=c_char,len=*), INTENT(IN) :: kernel
    TYPE ( op_set ) , INTENT(IN) :: set

    {% for arg in parloop.args %}
    TYPE ( op_arg ) , INTENT(IN) :: opArg{{ arg.i+1 }}
    {% endfor %}

    IF (getHybridGPU().EQ.1) THEN
      CALL op_par_loop_{{ parloop.name }}_host_gpu( &
        & kernel, &
        & set, &
        {% for arg in parloop.args %}
        & opArg{{ arg.i+1 }}{{ comma(loop) }} &            
        {% endfor %}
      & )
    END IF
  END SUBROUTINE


  ! Stub for GPU execution
  attributes (host) SUBROUTINE op_par_loop_{{ parloop.name }}_host_gpu( &
    & kernel, &
    & set, &
    {% for arg in parloop.args %}
    & opArg{{ arg.i+1 }}{{ comma(loop) }} &            
    {% endfor %}
  & )

    IMPLICIT NONE
    character(kind=c_char,len=*), INTENT(IN) :: kernel
    TYPE ( op_set ) , INTENT(IN) :: set

    {% for arg in parloop.args %}
    TYPE ( op_arg ) , INTENT(IN) :: opArg{{ arg.i+1 }}
    {% endfor %}

    TYPE ( op_arg ) , DIMENSION({{ parloop.args | length }}) :: opArgArray
    INTEGER(kind=4) :: numberOfOpDats
    INTEGER(kind=4) :: n_upper
    INTEGER(kind=4), DIMENSION(1:8) :: timeArrayStart
    INTEGER(kind=4), DIMENSION(1:8) :: timeArrayEnd
    REAL(kind=8) :: startTime
    REAL(kind=8) :: endTime
    INTEGER(kind=4) :: returnSetKernelTiming

    {# Direct #}
    {% for arg in parloop.directs %}
    {{ arg.typ }}, DIMENSION(:), DEVICE, POINTER :: dirDat_{{ arg.var }}
    {% endfor %}
    {# Indirects #}
    {% for arg in parloop.indirectVars %}
    {{ arg.typ }}, DIMENSION(:), DEVICE, POINTER :: indDat_{{ arg.var }}
    {% endfor %}
    {# Maps #}
    {% for arg in parloop.indirectMaps %}
    INTEGER(kind=4), DIMENSION(:), DEVICE, POINTER :: map_{{ arg.map }}
    {% endfor %}

    {% for arg in parloop.globals %}
    INTEGER(kind=4) :: opDat{{ arg.i+1 }}Cardinality
    {% endfor %}
    {% for arg in parloop.directs %}
    INTEGER(kind=4) :: opDat{{ arg.i+1 }}Cardinality
    {% endfor %}
    {% for arg in parloop.indirectVars %}
    INTEGER(kind=4) :: opDat{{ arg.i+1 }}Cardinality
    {% endfor %}
    {% for arg in parloop.indirectMaps %}
    INTEGER(kind=4) :: opMap{{ arg.i+1 }}Cardinality
    {% endfor %}

    INTEGER(kind=4) :: threadsPerBlock
    INTEGER(kind=4) :: blocksPerGrid
    INTEGER(kind=4) :: dynamicSharedMemorySize
    INTEGER(kind=4) :: threadSynchRet
    INTEGER(kind=4) :: i1
    INTEGER(kind=4) :: i2
    INTEGER(kind=4) :: i10
    {# Indirection #}
    {% if parloop.indirection %}
    TYPE ( op_plan ) , POINTER :: actualPlan

    INTEGER(kind=4), DIMENSION(1:{{ parloop.args | length }}) :: opDatArray
    INTEGER(kind=4), DIMENSION(1:{{ parloop.args | length }}) :: mappingIndicesArray
    INTEGER(kind=4), DIMENSION(1:{{ parloop.args | length }}) :: accessDescriptorArray
    INTEGER(kind=4), DIMENSION(1:{{ parloop.args | length }}) :: indirectionDescriptorArray

    INTEGER(kind=4) :: numberOfIndirectOpDats
    INTEGER(kind=4) :: blockOffset
    {% if atomics %}
    INTEGER(kind=4) :: itstart, itend
    {% else %}
    INTEGER(kind=4), DIMENSION(:), DEVICE, POINTER :: pcol_reord
    INTEGER(kind=4), DIMENSION(:), POINTER :: color2_offsets
    {% endif %}
    INTEGER(kind=4) :: partitionSize
    INTEGER(kind=4) :: blockSize
    {# No indirection #}
    {% else %}
    INTEGER(kind=4) :: i20
    REAL(kind=4) :: dataTransfer
    {% endif %}

    INTEGER(kind=4), SAVE :: calledTimes=0
    INTEGER(kind=4) :: istat

    {% for arg in parloop.globals %}
    {%   if arg.acc == 'OP_WRITE' or arg is without_dim or arg.dim > 1 %}
    {{ arg.typ }}, DIMENSION(:), POINTER :: opDat{{ arg.i+1 }}Host
    {%   else %}
    {{ arg.typ }}, POINTER :: opDat{{ arg.i+1 }}Host
    {%     if arg.acc == 'OP_READ' and arg is not without_dim and arg.dim == 1 %}
    {{ arg.typ }} :: opDat{{ arg.i+1 }}Host_tmp {# XLF workaround #}
    {%     endif %}
    {%   endif %}
    {%   if arg.acc in ['OP_INC', 'OP_MAX', 'OP_MIN'] %}
    {{ arg.typ }}, DIMENSION(:), ALLOCATABLE :: reductionArrayHost{{ arg.i+1 }}
    {%     if arg is without_dim %}
    INTEGER(kind=4) :: scratchDevice{{ arg.i+1 }}Size
    {%     endif %}
    INTEGER(kind=4) :: reductionCardinality{{ arg.i+1 }}
    {%   endif %}
    {% endfor %}

    {# TODO: Optargs #}

    numberOfOpDats = {{ parloop.args | length }}

    {% for arg in parloop.args %}
    opArgArray({{ arg.i+1 }}) = opArg{{ arg.i+1 }}
    {% endfor %}

    returnSetKernelTiming = setKernelTime( &
      & {{ id }}, kernel//C_NULL_CHAR, 0.0_8, 0.00000_4,0.00000_4, 0 &
    & )

    {# TODO: Managing constants #}
    call op_timers_core(startTime)

    n_upper = op_mpi_halo_exchanges_cuda(set%setCPtr, numberOfOpDats, opArgArray)
    threadsPerBlock = getBlockSize(kernel//C_NULL_CHAR, set%setPtr%size)

    {% if parloop.indirection %}
    {# Indirection #}
    {% for i in parloop.indirectionDescriptor %}
    indirectionDescriptorArray({{ loop.index }}) = {{ i }}
    {% endfor %}

    numberOfIndirectOpDats = {{ parloop.indirectVars | length }}

    partitionSize = getPartitionSize(kernel//C_NULL_CHAR, set%setPtr%size)

    {% if not atomics %}
    planReturn = FortranPlanCaller( &
      & kernel//C_NULL_CHAR, &
      & set%setCPtr, &
      & partitionSize, &
      & numberOfOpDats, &
      & opArgArray, &
      & numberOfIndirectOpDats, &
      & indirectionDescriptorArray, &
      & 4 &
    & )
    {% endif %}

    {% else %}
    {# No indirection #}
    blocksPerGrid = {{ 200 if unknown_reduction_size else 600 }}
    dynamicSharedMemorySize = reductionSize(opArgArray,numberOfOpDats) * threadsPerBlock
    {% endif %}

    {# Globals #}
    {% for arg in parloop.globals %}
    opDat{{ arg.i+1 }}Cardinality = opArg{{ arg.i+1 }}%dim
    {% endfor %}
    {# Directs #}
    {% for arg in parloop.directs %}
    opDat{{ arg.i+1 }}Cardinality = opArg{{ arg.i+1 }}%dim * getSetSizeFromOpArg(opArg{{ arg.i+1 }})
    {% endfor %}
    {# Indirects #}
    {% for arg in parloop.indirectVars %}
    opDat{{ arg.i+1 }}Cardinality = opArg{{ arg.i+1 }}%dim * getSetSizeFromOpArg(opArg{{ arg.i+1 }})
    {% endfor %}
    {# Maps #}
    {% for arg in parloop.indirectMaps %}
    opMap{{ arg.i+1 }}Cardinality = set%setPtr%size * getMapDimFromOpArg(opArg{{ arg.i+1 }})
    {% endfor %}

    {# Globals #}
    {% for arg in parloop.globals %}
    {%   if arg.acc == 'OP_WRITE' or arg is without_dim or arg.dim > 1 %}
    CALL c_f_pointer(opArg{{ arg.i+1 }}%data, opDat{{ arg.i+1 }}Host, (/opDat{{ arg.i+1 }}Cardinality/))
    {%   else %}
    CALL c_f_pointer(opArg{{ arg.i+1 }}%data, opDat{{ arg.i+1 }}Host)
    {%     if accs[g_m] == 'OP_READ' and arg is not without_dim and arg.dim == 1 %}
    opDat{{ arg.i+1 }}Host_tmp = opDat{{ arg.i+1 }}Host {# XLF workaround #}
    {%     endif %}
    {%   endif %}
    {% endfor %}
    {# Directs #}
    {% for arg in parloop.directs %}
    CALL c_f_pointer(opArg{{ arg.i+1 }}%data_d, dirDat_{{ arg.var }}, (/opDat{{ arg.i+1 }}Cardinality/))
    {% endfor %}
    {# Indirects #}
    {% for arg in parloop.indirectVars %}
    CALL c_f_pointer(opArg{{ arg.i+1 }}%data_d, indDat_{{ arg.var }}, (/opDat{{ arg.i+1 }}Cardinality/))
    {% endfor %}
    {# Maps #}
    {% for arg in parloop.indirectMaps %}
    CALL c_f_pointer(opArg{{ arg.i+1 }}%map_data_d, map_{{ arg.map }}, (/opMap{{ arg.i+1 }}Cardinality/))
    {% endfor %}

    {% if parloop.indirection and not atomics %}
    CALL c_f_pointer(planReturn, actualPlan)
    CALL c_f_pointer(actualPlan%color2_offsets,color2_offsets, (/actualPlan%ncolors+1/))
    CALL c_f_pointer(actualPlan%col_reord,pcol_reord, (/set%setPtr%size+set%setPtr%exec_size/))
    {% endif %}

    {% for arg in parloop.globals %}
    {% if arg.acc == 'OP_READ' and arg.dim > 1 %}
    IF (.not. allocated(reductionArrayDevice{{ arg.i+1 }}update)) THEN
      allocate(reductionArrayDevice{{ arg.i+1 }}update(opArg{{ arg.i+1 }}%dim))
    END IF
    reductionArrayDevice{{ arg.i+1 }}update(1:opArg{{ arg.i+1 }}%dim) = opDat{{ arg.i+1 }}Host(1:opArg{{ arg.i+1 }}%dim) 
    {% endif %}
    {% endfor %}

    {% if parloop.indirection and parloop.reduction %}
    blocksPerGrid=0
    {% if atomics %}
    blocksPerGrid = (set%setPtr%size+set%setPtr%exec_size-1)/threadsPerBlock+1
    {% else %}
    DO i2 = 0, actualPlan%ncolors - 1, 1
      blocksPerGrid = blocksPerGrid+(color2_offsets(i2+2)-color2_offsets(i2+1)-1)/threadsPerBlock+1
    END DO
    {% endif %}
    {% endif %}

    {# Setup for reduction #}
    {% for arg in parloop.globals %}
    {% if arg.acc != 'OP_READ' %}
    reductionCardinality{{ arg.i+1 }} = blocksPerGrid * 1
    allocate( reductionArrayHost{{ arg.i+1 }}(reductionCardinality{{ arg.i+1 }} * {{ arg.dim }}) )
    IF (.not. allocated(reductionArrayDevice{{ arg.i+1 }}update)) THEN
      allocate( reductionArrayDevice{{ arg.i+1 }}update(reductionCardinality{{ arg.i+1 }} * {{ arg.dim }}) )
    END IF

    DO i10 = 0, reductionCardinality{{ arg.i+1 }} - 1, 1
    {% if arg.dim == 1 %}
      reductionArrayHost{{ arg.i+1 }}(i10+1) = {{ 0.0 if arg.acc == 'OP_INC' else 'opDatHost' }}
    {% else %}
      reductionArrayHost{{ arg.i+1 }}(i10 * ({{ arg.dim }}) + 1 : i10 * ({{ arg.dim }}) + ({{ arg.dim }})) = {{ 0.0 if arg.acc == 'OP_INC' else 'opDatHost' }}
    {% endif %}
    END DO
 
    reductionArrayDevice{{ arg.i+1 }}update = reductionArrayHost{{ arg.i+1 }}
    {% endif %}
    {% endfor %}

    {% if unknown_reduction_size %}
    {#  #}
    {% endif %}

    {% if parloop.indirection %}
    {# Indirection #}
    {% if atomics %} 
    DO i2 = 0, 2 - 1, 1
      IF (i2 .EQ. 1) THEN
        itstart = set%setPtr%core_size
        itend = n_upper
        CALL op_mpi_wait_all_cuda(numberOfOpDats, opArgArray)
      ELSE
        itstart = 0
        itend = set%setPtr%core_size
      END IF

      blocksPerGrid = (itend-itstart-1)/threadsPerBlock+1
    {% else %} 
    DO i2 = 0, actualPlan%ncolors - 1, 1
      IF (i2 .EQ. actualPlan%ncolors_core) THEN
        CALL op_mpi_wait_all_cuda(numberOfOpDats, opArgArray)
      END IF

      blocksPerGrid = (color2_offsets(i2+2)-color2_offsets(i2+1)-1)/threadsPerBlock+1
    {% endif %} 
      dynamicSharedMemorySize = reductionSize(opArgArray, numberOfOpDats) * threadsPerBlock

      CALL {{ parloop.name }}_cuda_wrap <<<blocksPerGrid,threadsPerBlock,dynamicSharedMemorySize>>>( &
        {# Globals #}
        {% for arg in parloop.globals %}
        {# & gblDat_{{ arg.var }}, & #}
        {% endfor %}
        {# Directs #}
        {% for arg in parloop.directs %}
        & dirDat_{{ arg.var }}, &
        {% endfor %}
        {# Indirects #}
        {% for arg in parloop.indirectVars %}
        & indDat_{{ arg.var }}, &
        {% endfor %}
        {# Maps #}
        {% for arg in parloop.indirectMaps %}
        & map_{{ arg.map }}, &
        {% endfor %}
        {% if atomics %}
        & itstart, &
        & itend, &
        {% else %}
        & color2_offsets(i2+1), &
        & color2_offsets(i2+2), &
        & pcol_reord, &
        {% endif %}
        & set%setPtr%size+set%setPtr%exec_size &
      & )

    END DO
    {% else %}
    {# No indirection #}
    CALL {{ parloop.name }}_cuda_wrap <<<blocksPerGrid,threadsPerBlock,dynamicSharedMemorySize>>>( &
      {# Globals #}
      {% for arg in parloop.globals %}
      {# & gblDat_{{ arg.var }}, & #}
      {% endfor %}
      {# Directs #}
      {% for arg in parloop.directs %}
      & dirDat_{{ arg.var }}, &
      {% endfor %}
      & set%setPtr%size &
    & )
    {% endif %}

    {% if not atomics %}
    IF ((n_upper .EQ. 0) .OR. (n_upper .EQ. set%setPtr%core_size)) THEN
      CALL op_mpi_wait_all_cuda(numberOfOpDats, opArgArray)
    END IF
    {% endif%}

    CALL op_mpi_set_dirtybit_cuda(numberOfOpDats, opArgArray)

    {# Reductions #}
    {% for arg in parloop.globals %} {# TODO: Maybe add reductions prop #}
    {% if arg.acc != 'OP_READ' %}
    {% call op_opt(arg) %} 
    reductionArrayHost{{ arg.i+1 }} = reductionArrayDevice{{ arg.i+1 }}update
    DO i10 = 0, reductionCardinality{{ arg.i+1 }} - 1, 1
    {% if arg.acc == 'OP_INC' %}
      {# opDat{{ arg.i+1 }}Host = opDat{{ arg.i+1 }}Host + reductionArrayHost{{ arg.i+1 }}(i10+1) #}
      opDat{{ arg.i+1 }}Host(1:{{ arg.dim }}) = opDat{{ arg.i+1 }}Host(1:{{ arg.dim }}) + reductionArrayHost{{ arg.i+1 }}(i10 * ({{ arg.dim }}) + 1 : i10 * ({{ arg.dim }}) + ({{ arg.dim }}))
    {% elif arg.acc == 'OP_MIN' %}
      {# opDat{{ arg.i+1 }}Host = MIN(opDat{{ arg.i+1 }}Host , reductionArrayHost{{ arg.i+1 }}(i10+1)) #}
      opDat{{ arg.i+1 }}Host(1:{{ arg.dim }}) = MIN(opDat{{ arg.i+1 }}Host(1:{{ arg.dim }}) , reductionArrayHost{{ arg.i+1 }}(i10 * ({{ arg.dim }}) + 1 : i10 * ({{ arg.dim }}) + ({{ arg.dim }})))
    {% elif arg.acc == 'OP_MAX' %}
      {# opDat{{ arg.i+1 }}Host = MAX(opDat{{ arg.i+1 }}Host , reductionArrayHost{{ arg.i+1 }}(i10+1)) #}
      opDat{{ arg.i+1 }}Host(1:{{ arg.dim }}) = MAX(opDat{{ arg.i+1 }}Host(1:{{ arg.dim }}) , reductionArrayHost{{ arg.i+1 }}(i10 * ({{ arg.dim }}) + 1 : i10 * ({{ arg.dim }}) + ({{ arg.dim }})))
    {% endif %}
    END DO
    {% endcall %}
    {#  #}
    deallocate( reductionArrayHost{{ arg.i+1 }} )
    {#  #}
    {% call op_opt(arg) %} 
    {% if arg.typ == OP.Float(64) %}
    CALL op_mpi_reduce_double(opArg{{ arg.i+1 }}, opArg{{ arg.i+1 }}%data)
    {% elif arg.typ == OP.Float(32) %}
    CALL op_mpi_reduce_float(opArg{{ arg.i+1 }}, opArg{{ arg.i+1 }}%data)
    {% elif arg.typ in OP.Int(True, 32) %}
    CALL op_mpi_reduce_int(opArg{{ arg.i+1 }}, opArg{{ arg.i+1 }}%data)
    {% elif arg.typ in OP.Bool() %}
    CALL op_mpi_reduce_bool(opArg{{ arg.i+1 }}, opArg{{ arg.i+1 }}%data)
    {% endif %}
    {% endcall %}
    {#  #}
    {% endif %}
    {% endfor %}
    
    istat = cudaDeviceSynchronize()
    call op_timers_core(endTime)

    {# Data transfers #}
    {% if not parloop.indirection %}
    dataTransfer = 0.0
    {% for arg in parloop.args %}
    dataTransfer = dataTransfer + opArg{{ arg.i+1 }}%size 
    {%- if arg is not global %} * getSetSizeFromOpArg(opArg{{ arg.i+1 }}){% endif %} 
    {%- if arg is not r_or_w_acc %} * 2.d0{% endif %}

    {% endfor %}
    {% endif %}

    returnSetKernelTiming = setKernelTime( &
      & {{ id }}, kernel//C_NULL_CHAR, &
      & endTime-startTime, &
      {% if parloop.indirection %}
      {% if atomics %}
      & 0.00000_4, 0.00000_4, &
      {% else %}
      & actualPlan%transfer, actualPlan%transfer2, &
      {% endif %}
      {% else %}
      & dataTransfer, 0.00000_4, &
      {% endif %}
      & 1 &
    & )

    calledTimes = calledTimes + 1
    
  END SUBROUTINE

END MODULE

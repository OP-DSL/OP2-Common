module res_calc_cuda_module

  use OP2_C
  use cudaConfigurationParams
  use constantVarsCuda
  use OP2Profiling
  use cudafor

  type varSizes_res_calc

    integer(4) :: pindArg0Size
    integer(4) :: pindArg0MapsSize
    integer(4) :: pindArg1Size
    integer(4) :: pindArg1MapsSize
    integer(4) :: pindArg2Size
    integer(4) :: pindArg2MapsSize
    integer(4) :: pindArg3Size
    integer(4) :: pindArg3MapsSize
    integer(4) :: parg0MapsSize
    integer(4) :: parg1MapsSize
    integer(4) :: parg2MapsSize
    integer(4) :: parg3MapsSize
    integer(4) :: parg4MapsSize
    integer(4) :: parg5MapsSize
    integer(4) :: parg6MapsSize
    integer(4) :: parg7MapsSize
    integer(4) :: pindArgSizesSize
    integer(4) :: pindArgOffsSize
    integer(4) :: pblkMapSize
    integer(4) :: pOffsetSize
    integer(4) :: pNelemsSize
    integer(4) :: pNcolorsSize
    integer(4) :: pColorsSize

  end type varSizes_res_calc

  real(8), constant :: res_calc_gam, &
                       res_calc_gm1, &
                       res_calc_cfl, &
                       res_calc_eps, &
                       res_calc_mach, &
                       res_calc_alpha, &
                       res_calc_air_const, &
                       res_calc_qinf(4)

  ! logical that tells if the input data to the kernel has been already generated
  ! by previous calls to this same op_par_loop function
  logical :: isKernelInputDataGenerated = .false.


  ! input data to kernel and associated variables
  integer(4) :: arg0Size, arg2Size, arg4Size, arg6Size
  type(varSizes_res_calc), device :: argSizes
  type(c_ptr) :: planRet


! real(8), dimension(:), allocatable, device :: argument0
! real(8), dimension(:), allocatable, device :: argument2
! real(8), dimension(:), allocatable, device :: argument4
! real(8), dimension(:), allocatable, device :: argument6
! type(op_plan), pointer :: actualPlan
! integer, pointer, dimension(:) :: ncolblk
! integer, pointer, dimension(:) :: pnindirect
! type(c_devptr), pointer, dimension(:) :: pindMaps
! integer(4), dimension(1) :: pindMapsSize
! integer, allocatable, device, dimension(:) :: pindMaps1
! integer(4) :: pindMaps1Size
! integer, allocatable, device, dimension(:) :: pindMaps2
! integer(4) :: pindMaps2Size
! integer, allocatable, device, dimension(:) :: pindMaps3
! integer(4) :: pindMaps3Size
! integer, allocatable, device, dimension(:) :: pindMaps4
! integer(4) :: pindMaps4Size
! type(c_devptr), pointer, dimension(:) :: pmaps
! integer(4), dimension(6) :: pmapsSize ! dimension = argsNumber (= 6, see below)
!!  integer(2), allocatable, device, dimension(:) :: pMaps1
! integer(2), allocatable, device, dimension(:) :: pMaps2
! integer(2), allocatable, device, dimension(:) :: pMaps3
! integer(2), allocatable, device, dimension(:) :: pMaps4
! integer(2), allocatable, device, dimension(:) :: pMaps5
! integer(2), allocatable, device, dimension(:) :: pMaps6
! integer(2), allocatable, device, dimension(:) :: pMaps7
! integer(2), allocatable, device, dimension(:) :: pMaps8
! integer(4) :: pmaps1Size, pmaps2Size, pmaps3Size, pmaps4Size, pmaps5Size, pmaps6Size, pmaps7Size, pmaps8Size
! integer, device, allocatable, dimension(:) :: pindSizes
! integer(4) :: pindSizesSize
! integer, device, allocatable, dimension(:) :: pindOffs
! integer(4) :: pindOffsSize
! integer, device, allocatable, dimension(:) :: pblkMap
! integer(4) :: pblkMapSize
! integer, device, allocatable, dimension(:) :: poffset
! integer(4) :: poffsetSize
! integer, device, allocatable, dimension(:) :: pnelems
! integer(4) :: pnelemsSize
! integer, device, allocatable, dimension(:) :: pnthrcol
! integer(4) :: pnthrcolSize
! integer, device, allocatable, dimension(:) :: pthrcol
! integer(4) :: pthrcolSize

contains

  attributes(host) subroutine res_calc_initialiseConstants ()

    implicit none

    real(8) :: p, r, u, e

    res_calc_gam = 1.400000
    res_calc_gm1 = 0.400000
    res_calc_cfl = 0.900000
    res_calc_eps = 0.050000
    res_calc_alpha = 0.052360

    res_calc_qinf(1) = 1.000000 ! r
    res_calc_qinf(2) = 0.473286 ! r * u
    res_calc_qinf(3) = 0.000000 ! 0.0
    res_calc_qinf(4) = 2.612000 ! r * e


!     res_calc_gam = 1.4
!     res_calc_gm1 = 1.4 - 1.0 ! the first operand was a reference to the gam variable...not accepted by Fortran CUDA
!     res_calc_cfl = 0.9
!     res_calc_eps = 0.05
!
!     res_calc_mach  = 0.4
!     res_calc_alpha = 3.0 * atan(1.0) / 45.0
!     p     = 1.0
!     r     = 1.0
!     u     = sqrt ( res_calc_gam * p / r ) * res_calc_mach
!     e     = p / ( r * res_calc_gm1 ) + 0.5 * u * u
!
!     res_calc_qinf(1) = r
!     res_calc_qinf(2) = r * u
!     res_calc_qinf(3) = 0.0
!     res_calc_qinf(4) = r * e

  end subroutine res_calc_initialiseConstants


  ! user kernel, with formal arguments modified
  attributes(device) subroutine res_calc ( x1, x2, q1, q2, adt1, adt2, res1, res2 )

    implicit none

    ! formal parameters
    real(8), dimension(2), shared :: x1
    real(8), dimension(2), shared :: x2
    real(8), dimension(4), shared :: q1
    real(8), dimension(4), shared :: q2
    real(8), dimension(1), shared :: adt1
    real(8), dimension(1), shared :: adt2
    real(8), dimension(4) :: res1
    real(8), dimension(4) :: res2

    ! local variables
    real(8) :: dx, dy, mu, ri, p1, vol1, p2, vol2, f

    dx = x1(1) - x2(1)
    dy = x1(2) - x2(2)

    ri   = 1.0 / q1(1)
    p1   = res_calc_gm1 * (q1(4)-0.5 * ri * (q1(2)*q1(2)+q1(3)*q1(3)))
    vol1 =  ri * (q1(2)*dy - q1(3)*dx)

    ri   = 1.0 / q2(1)
    p2   = res_calc_gm1 * (q2(4)-0.5 * ri*(q2(2)*q2(2)+q2(3)*q2(3)))
    vol2 =  ri * (q2(2)*dy - q2(3)*dx)


    mu = 0.5 * ((adt1(1))+(adt2(1))) * res_calc_eps


    f = 0.5 * (vol1 * q1(1)         + vol2* q2(1)        ) + mu*(q1(1)-q2(1))
    res1(1) = res1(1) + f
    res2(1) = res2(1) - f

    f = 0.5 * (vol1* q1(2) + p1*dy + vol2* q2(2) + p2*dy) + mu*(q1(2)-q2(2))
    res1(2) = res1(2) + f
    res2(2) = res2(2) - f

    f = 0.5 * (vol1* q1(3) - p1*dx + vol2* q2(3) - p2*dx) + mu*(q1(3)-q2(3))
    res1(3) = res1(3) + f
    res2(3) = res2(3) - f

    f = 0.5 * (vol1*(q1(4)+p1)     + vol2*(q2(4)+p2)    ) + mu*(q1(4)-q2(4))
    res1(4) = res1(4) + f
    res2(4) = res2(4) - f

  end subroutine res_calc


  attributes(global) subroutine op_cuda_res_calc ( argSizes, &
                                                 & pindArg0, &
                                                 & pindArg0Maps, &
                                                 & pindArg1, &
                                                 & pindArg1Maps, &
                                                 & pindArg2, &
                                                 & pindArg2Maps, &
                                                 & pindArg3, &
                                                 & pindArg3Maps, &
                                                 & parg0Maps, &
                                                 & parg1Maps, &
                                                 & parg2Maps, &
                                                 & parg3Maps, &
                                                 & parg4Maps, &
                                                 & parg5Maps, &
                                                 & parg6Maps, &
                                                 & parg7Maps, &
                                                 & pindArgSizes, &
                                                 & pindArgOffs, &
                                                 & blockOffset, &
                                                 & pblkMap, &
                                                 & poffset, &
                                                 & pnelems, &
                                                 & pncolors, &
                                                 & pcolors &
                                               & )

    implicit none

    type(varSizes_res_calc), device :: argSizes
    integer(4), value :: blockOffset

    real(8), dimension(0:(argSizes%pindArg0Size)-1), device :: pindArg0
    integer(4), dimension(0:(argSizes%pindArg0MapsSize)-1), device :: pindArg0Maps

    real(8), dimension(0:(argSizes%pindArg1Size)-1), device :: pindArg1
    integer(4), dimension(0:(argSizes%pindArg1MapsSize)-1), device :: pindArg1Maps

    real(8), dimension(0:(argSizes%pindArg2Size)-1), device :: pindArg2
    integer(4), dimension(0:(argSizes%pindArg2MapsSize)-1), device :: pindArg2Maps

    real(8), dimension(0:(argSizes%pindArg3Size)-1), device :: pindArg3
    integer(4), dimension(0:(argSizes%pindArg3MapsSize)-1), device :: pindArg3Maps

    integer(2), dimension(0:(argSizes%parg0MapsSize)-1), device :: parg0Maps
    integer(2), dimension(0:(argSizes%parg1MapsSize)-1), device :: parg1Maps
    integer(2), dimension(0:(argSizes%parg2MapsSize)-1), device :: parg2Maps
    integer(2), dimension(0:(argSizes%parg3MapsSize)-1), device :: parg3Maps
    integer(2), dimension(0:(argSizes%parg4MapsSize)-1), device :: parg4Maps
    integer(2), dimension(0:(argSizes%parg5MapsSize)-1), device :: parg5Maps
    integer(2), dimension(0:(argSizes%parg6MapsSize)-1), device :: parg6Maps
    integer(2), dimension(0:(argSizes%parg7MapsSize)-1), device :: parg7Maps

    integer(4), dimension(0:(argSizes%pindArgSizesSize)-1), device :: pindArgSizes
    integer(4), dimension(0:(argSizes%pindArgOffsSize)-1), device :: pindArgOffs
    integer(4), dimension(0:(argSizes%pblkMapSize)-1), device :: pblkMap
    integer(4), dimension(0:(argSizes%pOffsetSize)-1), device :: poffset
    integer(4), dimension(0:(argSizes%pNelemsSize)-1), device :: pnelems
    integer(4), dimension(0:(argSizes%pNcolorsSize)-1), device :: pncolors
    integer(4), dimension(0:(argSizes%pColorsSize)-1), device :: pcolors

    ! the following variables are used to keep temporary values for OP_INC data (1 element)
    real(8), dimension(0:3) :: arg6_l
    real(8), dimension(0:3) :: arg7_l

    integer(4), shared :: ind_arg0_size
    integer(4), shared :: ind_arg1_size
    integer(4), shared :: ind_arg2_size
    integer(4), shared :: ind_arg3_size

    integer(4), shared :: nelems2
    integer(4), shared :: ncolor
    integer(4), shared :: nelem
    integer(4), shared :: offset_b
    integer(4), shared :: blockId

    ! the following shared variable is allocated by the kernel call (nshared parameter)
    ! in case of op_dats with different base data type, we can declare multiple
    ! myshared with different types, all related to the same address, and then properly
    ! access them
    real(8), shared :: myshared(0:*)

    integer :: nbytes0, nbytes1, nbytes2, nbytes3

    integer :: n, moduled, whileBound, col2, iterInit, i
    integer :: inRoundUp0, inRoundUp1, inRoundUp2, inRoundUp3

    integer(4) :: arg6_map, arg7_map
    integer(4) :: col

    if ( (threadidx%x -1) .eq. 0 ) then

      ! get sizes and shift pointers and direct-mapped data

      blockId = pblkmap((blockidx%x-1) + blockOffset )

      nelem = pnelems(blockId)
      offset_b = poffset(blockId)

      nelems2  = blockdim%x * ( 1 + ( nelem - 1 ) / blockdim%x )
      ncolor   = pncolors(blockId)

      ! ind_arg0_size = ind_arg_sizes[0+blockId*4];
      ! ind_arg1_size = ind_arg_sizes[1+blockId*4];
      ! ind_arg2_size = ind_arg_sizes[2+blockId*4];
      ! ind_arg3_size = ind_arg_sizes[3+blockId*4];

      ! in the *4 expression, 4 is equal to indsNumber
      ind_arg0_size = pindArgSizes(0 + blockId * 4)
      ind_arg1_size = pindArgSizes(1 + blockId * 4)
      ind_arg2_size = pindArgSizes(2 + blockId * 4)
      ind_arg3_size = pindArgSizes(3 + blockId * 4)

      ! merged up below in expressions for shared memory accesses, but useful to see them here!
!       ind_arg0_map = ind_arg0_maps + ind_arg_offs[0+blockId*4];
!       ind_arg1_map = ind_arg1_maps + ind_arg_offs[1+blockId*4];
!       ind_arg2_map = ind_arg2_maps + ind_arg_offs[2+blockId*4];
!       ind_arg3_map = ind_arg3_maps + ind_arg_offs[3+blockId*4];

      ! The strange bit operations below computes the ROUND_UP
      ! #define ROUND_UP(bytes) (((bytes) + 15) & ~15)
      ! The 8 below is sizeof(double), which in fortran is set with real(8)

!       int nbytes = 0;
!       ind_arg0_s = (double *) &shared[nbytes];
!       nbytes    += ROUND_UP(ind_arg0_size*sizeof(double)*2);
!       ind_arg1_s = (double *) &shared[nbytes];
!       nbytes    += ROUND_UP(ind_arg1_size*sizeof(double)*4);
!       ind_arg2_s = (double *) &shared[nbytes];
!       nbytes    += ROUND_UP(ind_arg2_size*sizeof(double)*1);
!       ind_arg3_s = (double *) &shared[nbytes];


      ! int nbytes = 0;
      ! nbytes    += ROUND_UP(ind_arg0_size*sizeof(double)*2);
      ! nbytes    += ROUND_UP(ind_arg1_size*sizeof(double)*4);
      ! nbytes    += ROUND_UP(ind_arg2_size*sizeof(double)*1);

!       do i = 0, 1800
!
!         myshared(i) = 0
!
!       end do

    end if
!     ! make sure all of above completed
    call syncthreads()

    inRoundUp0 = ind_arg0_size*2
    inRoundUp1 = ind_arg1_size*4
    inRoundUp2 = ind_arg2_size*1
!
    nbytes0 = 0
    nbytes1 = nbytes0 + inRoundUp0
    nbytes2 = nbytes1 + inRoundUp1
    nbytes3 = nbytes2 + inRoundUp2

    ! copy indirect datasets into shared memory or zero increment

    ! implements:
    ! for (int n=threadIdx.x; n<ind_arg0_size*2; n+=blockDim.x)
    !   ind_arg0_s[n] = ind_arg0[n%2+ind_arg0_map[n/2]*2];
    n = (threadidx%x-1)
    whileBound = ind_arg0_size * 2
    do while ( n .lt. whileBound )
      ! nbytes = 0 => 0 + ..
      moduled = mod ( n, 2 )

      ! remember that:
      !       ind_arg0_map = ind_arg0_maps + ind_arg_offs[0+blockId*4];
      ! and:
      !       ind_arg0_s = (double *) &shared[nbytes];
      myshared(nbytes0 + n) = pindArg0(moduled  + ( pindArg0Maps ( 0 + (pindArgOffs( 0 + blockId * 4 )) + ( n / 2 ) ) ) * 2)

      n = n + (blockdim%x)
    end do

    ! implements:
    ! for (int n=threadIdx.x; n<ind_arg1_size*4; n+=blockDim.x)
    !   ind_arg1_s[n] = ind_arg1[n%4+ind_arg1_map[n/4]*4];
    n = (threadidx%x-1)
    whileBound = ind_arg1_size * 4
    do while ( n .lt. whileBound )

      ! nbytes = 0 => 0 + ..
      moduled = mod ( n, 4 )

      ! remember that:
      !       ind_arg1_map = ind_arg1_maps + ind_arg_offs[1+blockId*4];
      ! and:
      !       nbytes    += ROUND_UP(ind_arg0_size*sizeof(double)*2); == nbytes1
      !       ind_arg1_s = (double *) &shared[nbytes];
      myshared(nbytes1 + n) = pindArg1(moduled  + ( pindArg1Maps ( 0 + pindArgOffs( 1 + blockId * 4 ) + ( n / 4 ) ) ) * 4)

      n = n + (blockdim%x)
    end do


    ! implements:
    ! for (int n=threadIdx.x; n<ind_arg2_size*1; n+=blockDim.x)
    !   ind_arg2_s[n] = ind_arg2[n%1+ind_arg2_map[n/1]*1];
    n = (threadidx%x-1)
    whileBound = ind_arg2_size * 1
    do while ( n .lt. whileBound )
      ! nbytes = 0 => 0 + ..
      moduled = mod ( n, 1 )

      ! remember that:
      !       ind_arg2_map = ind_arg2_maps + ind_arg_offs[2+blockId*4];
      ! and:
      !       nbytes    += ROUND_UP(ind_arg1_size*sizeof(double)*4); == nbytes2
      !       ind_arg2_s = (double *) &shared[nbytes];
      myshared(nbytes2 + n) = pindArg2(moduled  + ( pindArg2Maps ( 0 + pindArgOffs( 2 + blockId * 4 ) + ( n / 1 ) ) ) * 1)

      n = n + (blockdim%x)
    end do

    ! implements:
    ! for (int n=threadIdx.x; n<ind_arg3_size*4; n+=blockDim.x)
    !   ind_arg3_s[n] = ZERO_float;
    n = (threadidx%x-1)
    whileBound = ind_arg3_size * 4
    do while ( n .lt. whileBound )
      ! nbytes = 0 => 0 + ..
      !moduled = mod ( n, 2 )

      ! remember that:
      !       ind_arg3_map = ind_arg3_maps + ind_arg_offs[3+blockId*4];
      ! and:
      !       nbytes    += ROUND_UP(ind_arg2_size*sizeof(double)*1); == nbytes2
      !       ind_arg3_s = (double *) &shared[nbytes];
      myshared(nbytes3 + n) = 0

      n = n + (blockdim%x)
    end do

    ! make sure all of above completed
    call syncthreads()
!
    ! for (int n=threadIdx.x; n<nelems2; n+=blockDim.x) {
    ! process set elements
    n = (threadidx%x-1)
    do while ( n .lt. nelems2 )

      col2 = -1

      if ( n < nelem ) then

        ! initialise local variables
        do iterInit = 0, 3
          arg6_l(iterInit) = 0
        end do

        do iterInit = 0, 3
          arg7_l(iterInit) = 0
        end do

        ! call user kernel

        ! ind_arg0_s+arg0_maps[n+offset_b]*2
        ! ind_arg0_s+arg1_maps[n+offset_b]*2
        ! ind_arg1_s+arg2_maps[n+offset_b]*4
        ! ind_arg1_s+arg3_maps[n+offset_b]*4
        ! ind_arg2_s+arg4_maps[n+offset_b]*1,
        ! ind_arg2_s+arg5_maps[n+offset_b]*1,
        call res_calc ( myshared ( nbytes0 + parg0Maps (n + offset_b) * 2 : (nbytes0 + parg0Maps(n + offset_b) * 2) + 2 ), &
                        myshared ( nbytes0 + parg1Maps (n + offset_b) * 2 : (nbytes0 + parg1Maps(n + offset_b) * 2) + 2 ), &
                        myshared ( nbytes1 + parg2Maps (n + offset_b) * 4 : (nbytes1 + parg2Maps(n + offset_b) * 4) + 4 ), &
                        myshared ( nbytes1 + parg3Maps (n + offset_b) * 4 : (nbytes1 + parg3Maps(n + offset_b) * 4) + 4 ), &
                        myshared ( nbytes2 + parg4Maps (n + offset_b) * 1 : (nbytes2 + parg4Maps(n + offset_b) * 1) + 1 ), &
                        myshared ( nbytes2 + parg5Maps (n + offset_b) * 1 : (nbytes2 + parg5Maps(n + offset_b) * 1) + 1 ), &
                        arg6_l, &
                        arg7_l &
                      )

        ! col2 = colors[n+offset_b];
        col2 = pcolors(n + offset_b )

      end if

      ! int arg6_map = arg6_maps[n+offset_b];
      ! int arg7_map = arg7_maps[n+offset_b];
      arg6_map = parg6Maps ( n + offset_b )
      arg7_map = parg7Maps ( n + offset_b )

      ! for (int col=0; col<ncolor; col++) {
      do col = 0, ncolor-1

        if ( col2 .eq. col ) then

          ! for (int d=0; d<4; d++)
          do iterInit = 0, 3
            ! ind_arg3_s[d+arg6_map*4] += arg6_l[d];
            myshared(nbytes3 + iterInit + arg6_map*4 ) = myshared(nbytes3 + iterInit + arg6_map*4 ) + arg6_l(iterInit)
          end do

          ! for (int d=0; d<4; d++)
          do iterInit = 0, 3
            ! ind_arg3_s[d+arg7_map*4] += arg7_l[d];
            myshared(nbytes3 + iterInit + arg7_map*4 ) = myshared(nbytes3 + iterInit + arg7_map*4 ) + arg7_l(iterInit)
          end do

        end if

        ! make sure all of above completed
        call syncthreads()

      end do

      n = n + (blockdim%x)
    end do

    ! apply pointered write/increment

    ! for (int n=threadIdx.x; n<ind_arg3_size*4; n+=blockDim.x)
    !   ind_arg3[n%4+ind_arg3_map[n/4]*4] += ind_arg3_s[n];
    n = (threadidx%x-1)
    do while ( n < ind_arg3_size*4 )

      moduled = mod ( n, 4 )

      ! remember that:
      ! ind_arg3_map = ind_arg3_maps + ind_arg_offs[3+blockId*4];
      ! and that:
      ! ind_arg3_s = myshared(nbytes3)
      pindArg3 ( moduled + pindArg3Maps ( (0 + pindArgOffs ( 3 + blockId * 4 )) + (n / 4) ) * 4 ) = pindArg3 ( moduled + pindArg3Maps ( (0 + pindArgOffs ( 3 + blockId * 4 )) + (n / 4) ) * 4 ) + myshared(nbytes3 + n)

      n = n + (blockdim%x)
    end do

  end subroutine op_cuda_res_calc

  attributes(host) function op_par_loop_res_calc ( subroutineName, set, &
                                                 & arg0,   idx0, map0, access0, &
                                                 & arg1,   idx1, map1, access1, &
                                                 & arg2,   idx2, map2, access2, &
                                                 & arg3,   idx3, map3, access3, &
                                                 & arg4,   idx4, map4, access4, &
                                                 & arg5,   idx5, map5, access5, &
                                                 & arg6,   idx6, map6, access6, &
                                                 & arg7,   idx7, map7, access7  &
                                               & )

    ! use directives
    use, intrinsic :: ISO_C_BINDING
    use cudafor

    ! mandatory
    implicit none

    type(profInfo) :: op_par_loop_res_calc

    ! formal arguments
    character(kind=c_char,len=*), intent(in) :: subroutineName

    ! data set on which we loop
    type(op_set), intent(in) :: set

    ! data ids used in the function
    type(op_dat) :: arg0, arg1, arg2, arg3, arg4, arg5, arg6, arg7

    ! index to be used in first and second pointers
    integer(4), intent(in) :: idx0, idx1, idx2, idx3, idx4, idx5, idx6, idx7

    ! ptr ids for indirect access to data
    type(op_map) :: map0, map1, map2, map3, map4, map5, map6, map7

    ! access values for arguments
    integer(4), intent(in) :: access0, access1, access2, access3, access4, access5, access6, access7

    ! Compiler: variables used to invoke cplan
    integer(4) :: args(8), idxs(8), maps(8), accs(8), inds(8), argsTypes(8)
    integer(4) :: argsNumber, indsNumber
    integer(4) :: partitionSize

!   ! returned plan address by cplan and plan functions
!   type(c_ptr) :: planRet
!
!   ! variable for storing the actual OP Plan
    type(op_plan), pointer :: actualPlan

    ! iteration and offset variables to implement plan execution
    integer(4) :: blockOffset, col

    ! configuration variables for main kernel call
    integer(4) :: nblocks, nthread, nshared

    ! iteration variables
    integer(4) :: i, m, iter

    ! value returned by thread synchronisation function
    integer(4) :: threadsynchret

    ! Fortran variable for Host variable
    integer, pointer, dimension(:) :: ncolblk
!
    integer, pointer, dimension(:) :: pnindirect
!
!
!   ! ind_maps is an array of device pointers allocated on the host memory
    type(c_devptr), pointer, dimension(:) :: pindMaps
    integer(4), dimension(1) :: pindMapsSize
!
!   ! as many pindMapsI as the positions of pindMaps (4 in this case = indsNumber )
    integer, allocatable, device, dimension(:) :: pindMaps1
    integer(4) :: pindMaps1Size
!
    integer, allocatable, device, dimension(:) :: pindMaps2
    integer(4) :: pindMaps2Size
!
    integer, allocatable, device, dimension(:) :: pindMaps3
    integer(4) :: pindMaps3Size
!
    integer, allocatable, device, dimension(:) :: pindMaps4
    integer(4) :: pindMaps4Size
!
!   ! maps is an array of device pointers allocated on the host memory
    type(c_devptr), pointer, dimension(:) :: pmaps
    integer(4), dimension(6) :: pmapsSize ! dimension = argsNumber (= 6, see below)
!
!   ! as many pMapsI as the positions of pmaps (8 for this case) (they are short integers)
    integer(2), allocatable, device, dimension(:) :: pMaps1
    integer(2), allocatable, device, dimension(:) :: pMaps2
    integer(2), allocatable, device, dimension(:) :: pMaps3
    integer(2), allocatable, device, dimension(:) :: pMaps4
    integer(2), allocatable, device, dimension(:) :: pMaps5
    integer(2), allocatable, device, dimension(:) :: pMaps6
    integer(2), allocatable, device, dimension(:) :: pMaps7
    integer(2), allocatable, device, dimension(:) :: pMaps8
!
    integer(4) :: pmaps1Size, pmaps2Size, pmaps3Size, pmaps4Size, pmaps5Size, pmaps6Size, pmaps7Size, pmaps8Size
!
    integer, device, allocatable, dimension(:) :: pindSizes
    integer(4) :: pindSizesSize
!
    integer, device, allocatable, dimension(:) :: pindOffs
    integer(4) :: pindOffsSize
!
    integer, device, allocatable, dimension(:) :: pblkMap
    integer(4) :: pblkMapSize
!
    integer, device, allocatable, dimension(:) :: poffset
    integer(4) :: poffsetSize
!
    integer, device, allocatable, dimension(:) :: pnelems
    integer(4) :: pnelemsSize
!
    integer, device, allocatable, dimension(:) :: pnthrcol
    integer(4) :: pnthrcolSize
!
    integer, device, allocatable, dimension(:) :: pthrcol
    integer(4) :: pthrcolSize

    ! variables for marshalling data from host to device memory and back
!   integer(4) :: arg0Size, arg2Size, arg4Size, arg6Size
!
    real(8), dimension(:), allocatable, device :: argument0
    real(8), dimension(:), allocatable, device :: argument2
    real(8), dimension(:), allocatable, device :: argument4
    real(8), dimension(:), allocatable, device :: argument6
!
!   ! sizes of variables passed to kernel are all encapsulated inside a single struct
!   type(varSizes_res_calc), device :: argSizes

    ! profiling
    integer :: istat
    type (cudaEvent) :: startKernelTime, stopKernelTime, startHostTime, stopHostTime
    real(4) :: tmpHostTime

    ! create events
    istat = cudaEventCreate(startKernelTime)
    istat = cudaEventCreate(stopKernelTime)
    istat = cudaEventCreate(startHostTime)
    istat = cudaEventCreate(stopHostTime)

    istat = cudaEventRecord ( startHostTime, 0 )


    ! stage in of input arguments (transfer pointers + copy from host to device memory)

    if ( isKernelInputDataGenerated .eq. .false. ) then

!     isKernelInputDataGenerated = .true.

      ! filling up variables for building the plan
      args(1) = arg0%index
      args(2) = arg1%index
      args(3) = arg2%index
      args(4) = arg3%index
      args(5) = arg4%index
      args(6) = arg5%index
      args(7) = arg6%index
      args(8) = arg7%index

      idxs(1) = idx0
      idxs(2) = idx1
      idxs(3) = idx2
      idxs(4) = idx3
      idxs(5) = idx4
      idxs(6) = idx5
      idxs(7) = idx6
      idxs(8) = idx7

      ! when passing from OP2 Fortran to OP2 C++ we have to decrement the idx values (not 1->N, but 0->N-1)
      ! except -1 which indicates OP_ID or OP_GBL
      do iter = 1, 8
        if ( idxs(iter) /= -1 ) idxs(iter) = idxs(iter) - 1
      end do

      maps(1) = map0%index
      maps(2) = map1%index
      maps(3) = map2%index
      maps(4) = map3%index
      maps(5) = map4%index
      maps(6) = map5%index
      maps(7) = map6%index
      maps(8) = map7%index

      accs(1) = access0
      accs(2) = access1
      accs(3) = access2
      accs(4) = access3
      accs(5) = access4
      accs(6) = access5
      accs(7) = access6
      accs(8) = access7


      ! Compiler: generate this information by analysing the arguments
      argsNumber = 8
      indsNumber = 4 ! warning: this means the number of op_dat accessed indirectly, not the number of arguments!!

      inds(1) = 0
      inds(2) = 0
      inds(3) = 1
      inds(4) = 1
      inds(5) = 2
      inds(6) = 2
      inds(7) = 3
      inds(8) = 3

      if ( map0%dim .eq. -1 ) ! global data
        argsType(1) = F_OP_ARG_GBL
      else
        argsType(1) = F_OP_ARG_DAT
      end if

      if ( map1%dim .eq. -1 ) ! global data
        argsType(2) = F_OP_ARG_GBL
      else
        argsType(2) = F_OP_ARG_DAT
      end if

      if ( map2%dim .eq. -1 ) ! global data
        argsType(3) = F_OP_ARG_GBL
      else
        argsType(3) = F_OP_ARG_DAT
      end if

      if ( map3%dim .eq. -1 ) ! global data
        argsType(4) = F_OP_ARG_GBL
      else
        argsType(4) = F_OP_ARG_DAT
      end if

      if ( map4%dim .eq. -1 ) ! global data
        argsType(5) = F_OP_ARG_GBL
      else
        argsType(5) = F_OP_ARG_DAT
      end if

      if ( map5%dim .eq. -1 ) ! global data
        argsType(6) = F_OP_ARG_GBL
      else
        argsType(6) = F_OP_ARG_DAT
      end if

      if ( map6%dim .eq. -1 ) ! global data
        argsType(7) = F_OP_ARG_GBL
      else
        argsType(7) = F_OP_ARG_DAT
      end if

      if ( map7%dim .eq. -1 ) ! global data
        argsType(8) = F_OP_ARG_GBL
      else
        argsType(8) = F_OP_ARG_DAT
      end if

      partitionSize = 0

      ! get the plan
      planRet = cplan ( subroutineName, &
                      & set%index, &
                      & argsNumber, &
                      & args, &
                      & idxs, &
                      & maps, &
                      & accs, &
                      & indsNumber, &
                      & inds, &
                      & argsType, &
                      & partitionSize &
                   &  )

      call res_calc_initialiseConstants()

    end if

    ! 1. transfer C pointers to Fortran pointers
    arg0Size = arg0%dim * arg0%set%size
    call c_f_pointer ( arg0%dat_d, argument0, (/arg0Size/) )

    arg2Size = arg2%dim * arg2%set%size
    call c_f_pointer ( arg2%dat_d, argument2, (/arg2Size/) )

    arg4Size = arg4%dim * arg4%set%size
    call c_f_pointer ( arg4%dat_d, argument4, (/arg4Size/) )

    arg6Size = arg6%dim * arg6%set%size
    call c_f_pointer ( arg6%dat_d, argument6, (/arg6Size/) )

    ! convert arguments and plan data to Fortran pointers (not a copy!)
    ! Typically, first compute size, then transform pointer

    ! transform the returned C pointer to a type(op_plan) variable
    call c_f_pointer ( planRet, actualPlan )

    ! convert nindirect  used to generate the pindMapsSize array of sizes
    call c_f_pointer ( actualPlan%nindirect, pnindirect, (/indsNumber/) )

    ! convert pindMaps: there are indsNumber ind_maps
    call c_f_pointer ( actualPlan%ind_maps, pindMaps, (/indsNumber/) )

    ! convert first position of the pindMaps array (the size is stored in the corresponding pnindirect position)
    call c_f_pointer ( pindMaps(1), pindMaps1, pnindirect(1) )
    call c_f_pointer ( pindMaps(2), pindMaps2, pnindirect(2) )
    call c_f_pointer ( pindMaps(3), pindMaps3, pnindirect(3) )
    call c_f_pointer ( pindMaps(4), pindMaps4, pnindirect(4) )

    ! must be done for all indirect pointers: in this case 4 different arguments are accessed indirectly

    ! convert maps in op_plan: there are argsNumber maps
    call c_f_pointer ( actualPlan%maps, pmaps, (/argsNumber/) )

    ! convert positions in pmaps (only if the corresponding inds position is >= 0 (see op_support.cpp))
    ! can't do a do-loop because I can't generate variable name
    if ( inds(1) .ge. 0 ) then
      pmaps1Size = set%size
      call c_f_pointer ( pmaps(1), pmaps1, (/pmaps1Size/) )
    end if

    if ( inds(2) .ge. 0 ) then
      pmaps2Size = set%size
      call c_f_pointer ( pmaps(2), pmaps2, (/pmaps2Size/) )
    end if

    if ( inds(3) .ge. 0 ) then
      pmaps3Size = set%size
      call c_f_pointer ( pmaps(3), pmaps3, (/pmaps3Size/) )
    end if

    if ( inds(4) .ge. 0 ) then
      pmaps4Size = set%size
      call c_f_pointer ( pmaps(4), pmaps4, (/pmaps4Size/) )
    end if

    if ( inds(5) .ge. 0 ) then
      pmaps5Size = set%size
      call c_f_pointer ( pmaps(5), pmaps5, (/pmaps5Size/) )
    end if

    if ( inds(6) .ge. 0 ) then
      pmaps6Size = set%size
      call c_f_pointer ( pmaps(6), pmaps6, (/pmaps6Size/) )
    end if

    if ( inds(7) .ge. 0 ) then
      pmaps7Size = set%size
      call c_f_pointer ( pmaps(7), pmaps7, (/pmaps7Size/) )
    end if

    if ( inds(8) .ge. 0 ) then
      pmaps8Size = set%size
      call c_f_pointer ( pmaps(8), pmaps8, (/pmaps8Size/) )
    end if

    ! converting ncolblk field to fortran variable
    call c_f_pointer ( actualPlan%ncolblk, ncolblk, (/set%size/) )

    ! ind_sizes field has nblocks*indsNumber size
    pindSizesSize = actualPlan%nblocks * indsNumber
    call c_f_pointer ( actualPlan%ind_sizes, pindSizes, (/pindSizesSize/) )

    ! ind_offset field has the same dimension of ind_sizes
    pindOffsSize = pindSizesSize
    call c_f_pointer ( actualPlan%ind_offs, pindOffs, (/pindOffsSize/) )

    ! blkmap field has dimension nblocks
    pblkMapSize = actualPlan%nblocks
    call c_f_pointer ( actualPlan%blkmap, pblkMap, (/pblkMapSize/) )

    ! offset field has dimension nblocks
    poffsetSize = actualPlan%nblocks
    call c_f_pointer ( actualPlan%offset, poffset, (/poffsetSize/) )

    ! nelems field has dimension nblocks
    pnelemsSize = actualPlan%nblocks
    call c_f_pointer ( actualPlan%nelems, pnelems, (/pnelemsSize/) )

    ! nthrcol field has dimension nblocks
    pnthrcolSize = actualPlan%nblocks
    call c_f_pointer ( actualPlan%nthrcol, pnthrcol, (/pnthrcolSize/) )

    ! thrcol field has dimension set%size
    pthrcolSize = set%size
    call c_f_pointer ( actualPlan%thrcol, pthrcol, (/pthrcolSize/) )

    blockOffset = 0

    if ( isKernelInputDataGenerated .eq. .false. ) then

      isKernelInputDataGenerated = .true.


      ! sizes are compacted in a single struct, to save parameter space
      argSizes%pindArg0Size = arg0Size
      argSizes%pindArg0MapsSize = pnindirect(1)
      argSizes%pindArg1Size = arg2Size
      argSizes%pindArg1MapsSize = pnindirect(2)
      argSizes%pindArg2Size = arg4Size
      argSizes%pindArg2MapsSize = pnindirect(3)
      argSizes%pindArg3Size = arg6Size
      argSizes%pindArg3MapsSize = pnindirect(4)
      argSizes%parg0MapsSize = pMaps1Size
      argSizes%parg1MapsSize = pMaps2Size
      argSizes%parg2MapsSize = pMaps3Size
      argSizes%parg3MapsSize = pMaps4Size
      argSizes%parg4MapsSize = pMaps5Size
      argSizes%parg5MapsSize = pMaps6Size
      argSizes%parg6MapsSize = pMaps7Size
      argSizes%parg7MapsSize = pMaps8Size
      argSizes%pindArgSizesSize = pindSizesSize
      argSizes%pindArgOffsSize = pindOffsSize
      argSizes%pblkMapSize = pblkMapSize
      argSizes%pOffsetSize = poffsetSize
      argSizes%pNelemsSize = pnelemsSize
      argSizes%pNcolorsSize = pnthrcolSize
      argSizes%pColorsSize = pthrcolSize

    end if

    istat = cudaEventRecord ( stopHostTime, 0 )
    istat = cudaEventSynchronize ( stopHostTime )
    istat = cudaEventElapsedTime ( tmpHostTime, startHostTime, stopHostTime )

    op_par_loop_res_calc%hostTime = 0
    op_par_loop_res_calc%hostTime = op_par_loop_res_calc%hostTime + tmpHostTime
    tmpHostTime = 0


    istat = cudaEventRecord ( startKernelTime, 0 )

    ! execute the plan
    do col = 0, (actualPlan%ncolors-1)

      nblocks = ncolblk(col+1) !+1 is needed because ncolblk is indexed from 1:set%size and not from 0:set%size-1
      nthread = FOP_BLOCK_SIZE
      nshared = actualPlan%nshared

!     print *, 'col = ', col, nblocks, nthread, nshared

      ! call the main kernel (I need to add the variable sizes, otherwise we would get sigsegv in copy back)
      call op_cuda_res_calc <<< nblocks, nthread, nshared >>> ( argSizes, &
                                                                argument0, pindMaps1, &
                                                                argument2, pindMaps2, &
                                                                argument4, pindMaps3, &
                                                                argument6, pindMaps4, &
                                                                pMaps1, &
                                                                pMaps2, &
                                                                pMaps3, &
                                                                pMaps4, &
                                                                pMaps5, &
                                                                pMaps6, &
                                                                pMaps7, &
                                                                pMaps8, &
                                                                pindSizes, &
                                                                pindOffs, &
                                                                blockOffset, &
                                                                pblkMap, &
                                                                poffset, &
                                                                pnelems, &
                                                                pnthrcol, &
                                                                pthrcol &
                                                              )

      ! wait for the threads on device to terminate execution
      threadSynchRet = cudaThreadSynchronize()

      blockOffset = blockOffset + nblocks

    end do

    istat = cudaEventRecord ( stopKernelTime, 0 )
    istat = cudaEventSynchronize ( stopKernelTime )
    istat = cudaEventElapsedTime ( op_par_loop_res_calc%kernelTime, startKernelTime, stopKernelTime )

    istat = cudaEventRecord ( startHostTime, 0 )
    istat = cudaEventRecord ( stopHostTime, 0 )
    istat = cudaEventSynchronize ( stopHostTime )
    istat = cudaEventElapsedTime ( tmpHostTime, startHostTime, stopHostTime )

    op_par_loop_res_calc%hostTime = op_par_loop_res_calc%hostTime + tmpHostTime

  end function op_par_loop_res_calc

end module res_calc_cuda_module

module res_calc_cuda_module

	use OP2_C
	use cudaConfigurationParams
	use constantVarsCuda
	use OP2Profiling
	use cudafor

	type varSizes_res_calc
	
		integer(4) :: pindArg0Size
		integer(4) :: pindArg0MapsSize
		integer(4) :: pindArg1Size
		integer(4) :: pindArg1MapsSize
		integer(4) :: pindArg2Size
		integer(4) :: pindArg2MapsSize
		integer(4) :: pindArg3Size
		integer(4) :: pindArg3MapsSize
		integer(4) :: parg0MapsSize
		integer(4) :: parg1MapsSize
		integer(4) :: parg2MapsSize
		integer(4) :: parg3MapsSize
		integer(4) :: parg4MapsSize
		integer(4) :: parg5MapsSize
		integer(4) :: parg6MapsSize
		integer(4) :: parg7MapsSize
		integer(4) :: pindArgSizesSize
		integer(4) :: pindArgOffsSize
		integer(4) :: pblkMapSize
		integer(4) :: pOffsetSize
		integer(4) :: pNelemsSize
		integer(4) :: pNcolorsSize
		integer(4) :: pColorsSize
	
	end type varSizes_res_calc

	  real(8), constant :: res_calc_gam, &
												 res_calc_gm1, &
												 res_calc_cfl, &
												 res_calc_eps, &
												 res_calc_mach, &
												 res_calc_alpha, &
												 res_calc_air_const, &
												 res_calc_qinf(4)

	! logical that tells if the input data to the kernel has been already generated
	! by previous calls to this same op_par_loop function
	logical :: isKernelInputDataGenerated = .false.


	! input data to kernel and associated variables
	integer(4) :: arg0Size, arg2Size, arg4Size, arg6Size
	type(varSizes_res_calc), device :: argSizes
	type(c_ptr) :: planRet		


!	real(8), dimension(:), allocatable, device :: argument0
!	real(8), dimension(:), allocatable, device :: argument2
!	real(8), dimension(:), allocatable, device :: argument4
!	real(8), dimension(:), allocatable, device :: argument6
!	type(op_plan), pointer :: actualPlan
!	integer, pointer, dimension(:) :: ncolblk		
!	integer, pointer, dimension(:) :: pnindirect
!	type(c_devptr), pointer, dimension(:) :: pindMaps
!	integer(4), dimension(1) :: pindMapsSize
!	integer, allocatable, device, dimension(:) :: pindMaps1
!	integer(4) :: pindMaps1Size
!	integer, allocatable, device, dimension(:) :: pindMaps2
!	integer(4) :: pindMaps2Size
!	integer, allocatable, device, dimension(:) :: pindMaps3
!	integer(4) :: pindMaps3Size
!	integer, allocatable, device, dimension(:) :: pindMaps4
!	integer(4) :: pindMaps4Size
!	type(c_devptr), pointer, dimension(:) :: pmaps
!	integer(4), dimension(6) :: pmapsSize ! dimension = argsNumber (= 6, see below)
!!	integer(2), allocatable, device, dimension(:) :: pMaps1
!	integer(2), allocatable, device, dimension(:) :: pMaps2
!	integer(2), allocatable, device, dimension(:) :: pMaps3
!	integer(2), allocatable, device, dimension(:) :: pMaps4
!	integer(2), allocatable, device, dimension(:) :: pMaps5
!	integer(2), allocatable, device, dimension(:) :: pMaps6
!	integer(2), allocatable, device, dimension(:) :: pMaps7
!	integer(2), allocatable, device, dimension(:) :: pMaps8
!	integer(4) :: pmaps1Size, pmaps2Size, pmaps3Size, pmaps4Size, pmaps5Size, pmaps6Size, pmaps7Size, pmaps8Size
!	integer, device, allocatable, dimension(:) :: pindSizes
!	integer(4) :: pindSizesSize
!	integer, device, allocatable, dimension(:) :: pindOffs
!	integer(4) :: pindOffsSize
!	integer, device, allocatable, dimension(:) :: pblkMap
!	integer(4) :: pblkMapSize
!	integer, device, allocatable, dimension(:) :: poffset
!	integer(4) :: poffsetSize
!	integer, device, allocatable, dimension(:) :: pnelems
!	integer(4) :: pnelemsSize
!	integer, device, allocatable, dimension(:) :: pnthrcol
!	integer(4) :: pnthrcolSize
!	integer, device, allocatable, dimension(:) :: pthrcol
!	integer(4) :: pthrcolSize


	contains
	
		attributes(host) subroutine res_calc_initialiseConstants ()

			implicit none

			real(8) :: p, r, u, e

			res_calc_gam = 1.400000
			res_calc_gm1 = 0.400000
			res_calc_cfl = 0.900000
			res_calc_eps = 0.050000
			res_calc_alpha = 0.052360
			
			res_calc_qinf(1) = 1.000000 ! r
			res_calc_qinf(2) = 0.473286 ! r * u
			res_calc_qinf(3) = 0.000000 ! 0.0
			res_calc_qinf(4) = 2.612000 ! r * e


!			res_calc_gam = 1.4
!			res_calc_gm1 = 1.4 - 1.0 ! the first operand was a reference to the gam variable...not accepted by Fortran CUDA
!			res_calc_cfl = 0.9
!			res_calc_eps = 0.05
!
!			res_calc_mach  = 0.4
!			res_calc_alpha = 3.0 * atan(1.0) / 45.0
!			p     = 1.0
!			r     = 1.0
!			u     = sqrt ( res_calc_gam * p / r ) * res_calc_mach
!			e     = p / ( r * res_calc_gm1 ) + 0.5 * u * u
!
!			res_calc_qinf(1) = r
!			res_calc_qinf(2) = r * u
!			res_calc_qinf(3) = 0.0
!			res_calc_qinf(4) = r * e
		
		end subroutine res_calc_initialiseConstants
	
		
		! user kernel, with formal arguments modified
		attributes(device) subroutine res_calc ( x1, x2, q1, q2, adt1, adt2, res1, res2 )

			implicit none

			! formal parameters
			real(8), dimension(2), shared :: x1
			real(8), dimension(2), shared :: x2
			real(8), dimension(4), shared :: q1
			real(8), dimension(4), shared :: q2
			real(8), dimension(1), shared :: adt1
			real(8), dimension(1), shared :: adt2
			real(8), dimension(4) :: res1
			real(8), dimension(4) :: res2

			! local variables
			real(8) :: dx, dy, mu, ri, p1, vol1, p2, vol2, f

			dx = x1(1) - x2(1)
			dy = x1(2) - x2(2)

			ri   = 1.0 / q1(1)
			p1   = res_calc_gm1 * (q1(4)-0.5 * ri * (q1(2)*q1(2)+q1(3)*q1(3)))
			vol1 =  ri * (q1(2)*dy - q1(3)*dx)

			ri   = 1.0 / q2(1)
			p2   = res_calc_gm1 * (q2(4)-0.5 * ri*(q2(2)*q2(2)+q2(3)*q2(3)))
			vol2 =  ri * (q2(2)*dy - q2(3)*dx)


			mu = 0.5 * ((adt1(1))+(adt2(1))) * res_calc_eps


			f = 0.5 * (vol1 * q1(1)         + vol2* q2(1)        ) + mu*(q1(1)-q2(1))
			res1(1) = res1(1) + f
			res2(1) = res2(1) - f
			
			f = 0.5 * (vol1* q1(2) + p1*dy + vol2* q2(2) + p2*dy) + mu*(q1(2)-q2(2))
			res1(2) = res1(2) + f
			res2(2) = res2(2) - f
			
			f = 0.5 * (vol1* q1(3) - p1*dx + vol2* q2(3) - p2*dx) + mu*(q1(3)-q2(3))
			res1(3) = res1(3) + f
			res2(3) = res2(3) - f
			
			f = 0.5 * (vol1*(q1(4)+p1)     + vol2*(q2(4)+p2)    ) + mu*(q1(4)-q2(4))
			res1(4) = res1(4) + f
			res2(4) = res2(4) - f

		end subroutine res_calc


		attributes(global) subroutine op_cuda_res_calc ( argSizes, &
																									 & pindArg0, &
																									 & pindArg0Maps, &
																									 & pindArg1, &
																									 & pindArg1Maps, &
																									 & pindArg2, &
																									 & pindArg2Maps, &
																									 & pindArg3, &
																									 & pindArg3Maps, &
																									 & parg0Maps, &
																									 & parg1Maps, &
																									 & parg2Maps, &
																									 & parg3Maps, &
																									 & parg4Maps, &
																									 & parg5Maps, &
																									 & parg6Maps, &
																									 & parg7Maps, &
																									 & pindArgSizes, &
																									 & pindArgOffs, &
																									 & blockOffset, &
																									 & pblkMap, &
																									 & poffset, &
																									 & pnelems, &
																									 & pncolors, &
																									 & pcolors &
																								 & )

			implicit none
			
			type(varSizes_res_calc), device :: argSizes
			integer(4), value :: blockOffset
		
			real(8), dimension(0:(argSizes%pindArg0Size)-1), device :: pindArg0
			integer(4), dimension(0:(argSizes%pindArg0MapsSize)-1), device :: pindArg0Maps

			real(8), dimension(0:(argSizes%pindArg1Size)-1), device :: pindArg1
			integer(4), dimension(0:(argSizes%pindArg1MapsSize)-1), device :: pindArg1Maps

			real(8), dimension(0:(argSizes%pindArg2Size)-1), device :: pindArg2
			integer(4), dimension(0:(argSizes%pindArg2MapsSize)-1), device :: pindArg2Maps

			real(8), dimension(0:(argSizes%pindArg3Size)-1), device :: pindArg3
			integer(4), dimension(0:(argSizes%pindArg3MapsSize)-1), device :: pindArg3Maps

			integer(2), dimension(0:(argSizes%parg0MapsSize)-1), device :: parg0Maps
			integer(2), dimension(0:(argSizes%parg1MapsSize)-1), device :: parg1Maps
			integer(2), dimension(0:(argSizes%parg2MapsSize)-1), device :: parg2Maps
			integer(2), dimension(0:(argSizes%parg3MapsSize)-1), device :: parg3Maps
			integer(2), dimension(0:(argSizes%parg4MapsSize)-1), device :: parg4Maps
			integer(2), dimension(0:(argSizes%parg5MapsSize)-1), device :: parg5Maps
			integer(2), dimension(0:(argSizes%parg6MapsSize)-1), device :: parg6Maps
			integer(2), dimension(0:(argSizes%parg7MapsSize)-1), device :: parg7Maps
		
			integer(4), dimension(0:(argSizes%pindArgSizesSize)-1), device :: pindArgSizes
			integer(4), dimension(0:(argSizes%pindArgOffsSize)-1), device :: pindArgOffs
			integer(4), dimension(0:(argSizes%pblkMapSize)-1), device :: pblkMap
			integer(4), dimension(0:(argSizes%pOffsetSize)-1), device :: poffset
			integer(4), dimension(0:(argSizes%pNelemsSize)-1), device :: pnelems
			integer(4), dimension(0:(argSizes%pNcolorsSize)-1), device :: pncolors
			integer(4), dimension(0:(argSizes%pColorsSize)-1), device :: pcolors

			! the following variables are used to keep temporary values for OP_INC data (1 element)
			real(8), dimension(0:3) :: arg6_l
			real(8), dimension(0:3) :: arg7_l

			integer(4), shared :: ind_arg0_size
			integer(4), shared :: ind_arg1_size
			integer(4), shared :: ind_arg2_size
			integer(4), shared :: ind_arg3_size

			integer(4), shared :: nelems2
			integer(4), shared :: ncolor
			integer(4), shared :: nelem
			integer(4), shared :: offset_b
			integer(4), shared :: blockId

			! the following shared variable is allocated by the kernel call (nshared parameter)
			! in case of op_dats with different base data type, we can declare multiple 
			! myshared with different types, all related to the same address, and then properly
			! access them
			real(8), shared :: myshared(0:*)			
			
			integer :: nbytes0, nbytes1, nbytes2, nbytes3

			integer :: n, moduled, whileBound, col2, iterInit, i
			integer :: inRoundUp0, inRoundUp1, inRoundUp2, inRoundUp3
			
			integer(4) :: arg6_map, arg7_map
			integer(4) :: col
			
			if ( (threadidx%x -1) .eq. 0 ) then 
			
				! get sizes and shift pointers and direct-mapped data

				blockId = pblkmap((blockidx%x-1) + blockOffset )

				nelem = pnelems(blockId)
				offset_b = poffset(blockId)

				nelems2  = blockdim%x * ( 1 + ( nelem - 1 ) / blockdim%x )
				ncolor   = pncolors(blockId)

				! ind_arg0_size = ind_arg_sizes[0+blockId*4];                                   
 			  ! ind_arg1_size = ind_arg_sizes[1+blockId*4];                                   
			  ! ind_arg2_size = ind_arg_sizes[2+blockId*4];                                   
			  ! ind_arg3_size = ind_arg_sizes[3+blockId*4];                                   

				! in the *4 expression, 4 is equal to indsNumber 
				ind_arg0_size = pindArgSizes(0 + blockId * 4)
				ind_arg1_size = pindArgSizes(1 + blockId * 4)
				ind_arg2_size = pindArgSizes(2 + blockId * 4)
				ind_arg3_size = pindArgSizes(3 + blockId * 4)

				! merged up below in expressions for shared memory accesses, but useful to see them here!
!				ind_arg0_map = ind_arg0_maps + ind_arg_offs[0+blockId*4];
!				ind_arg1_map = ind_arg1_maps + ind_arg_offs[1+blockId*4];
!				ind_arg2_map = ind_arg2_maps + ind_arg_offs[2+blockId*4];
!				ind_arg3_map = ind_arg3_maps + ind_arg_offs[3+blockId*4];

				! The strange bit operations below computes the ROUND_UP
				! #define ROUND_UP(bytes) (((bytes) + 15) & ~15)				
				! The 8 below is sizeof(double), which in fortran is set with real(8)

!				int nbytes = 0;                                                               
!				ind_arg0_s = (double *) &shared[nbytes];                                       
!				nbytes    += ROUND_UP(ind_arg0_size*sizeof(double)*2);                         
!				ind_arg1_s = (double *) &shared[nbytes];                                       
!				nbytes    += ROUND_UP(ind_arg1_size*sizeof(double)*4);                         
!				ind_arg2_s = (double *) &shared[nbytes];                                       
!				nbytes    += ROUND_UP(ind_arg2_size*sizeof(double)*1);                         
!				ind_arg3_s = (double *) &shared[nbytes];                                       


				! int nbytes = 0;
				! nbytes    += ROUND_UP(ind_arg0_size*sizeof(double)*2);
				! nbytes    += ROUND_UP(ind_arg1_size*sizeof(double)*4);
				!	nbytes    += ROUND_UP(ind_arg2_size*sizeof(double)*1);

!				do i = 0, 1800
!				
!					myshared(i) = 0
!				
!				end do

			end if
!			! make sure all of above completed
			call syncthreads()

			inRoundUp0 = ind_arg0_size*2
			inRoundUp1 = ind_arg1_size*4
			inRoundUp2 = ind_arg2_size*1
!
			nbytes0 = 0
			nbytes1 = nbytes0 + inRoundUp0
			nbytes2 = nbytes1 + inRoundUp1
			nbytes3 = nbytes2 + inRoundUp2

			! copy indirect datasets into shared memory or zero increment

			! implements:
			! for (int n=threadIdx.x; n<ind_arg0_size*2; n+=blockDim.x)
			!		ind_arg0_s[n] = ind_arg0[n%2+ind_arg0_map[n/2]*2];
			n = (threadidx%x-1)
			whileBound = ind_arg0_size * 2
			do while ( n .lt. whileBound )
				! nbytes = 0 => 0 + ..
				moduled = mod ( n, 2 )
				
				! remember that:
				!				ind_arg0_map = ind_arg0_maps + ind_arg_offs[0+blockId*4];
				! and:
				!				ind_arg0_s = (double *) &shared[nbytes];
				myshared(nbytes0 + n) = pindArg0(moduled  + ( pindArg0Maps ( 0 + (pindArgOffs( 0 + blockId * 4 )) + ( n / 2 ) ) ) * 2)
				
				n = n + (blockdim%x)
			end do

			! implements:
			! for (int n=threadIdx.x; n<ind_arg1_size*4; n+=blockDim.x)
			!   ind_arg1_s[n] = ind_arg1[n%4+ind_arg1_map[n/4]*4];
			n = (threadidx%x-1)
			whileBound = ind_arg1_size * 4
			do while ( n .lt. whileBound )

				! nbytes = 0 => 0 + ..
				moduled = mod ( n, 4 )

				! remember that:
				!				ind_arg1_map = ind_arg1_maps + ind_arg_offs[1+blockId*4];
				! and:
				!				nbytes    += ROUND_UP(ind_arg0_size*sizeof(double)*2); == nbytes1
				!				ind_arg1_s = (double *) &shared[nbytes];
				myshared(nbytes1 + n) = pindArg1(moduled  + ( pindArg1Maps ( 0 + pindArgOffs( 1 + blockId * 4 ) + ( n / 4 ) ) ) * 4)
				
				n = n + (blockdim%x)
			end do									           


			! implements:
			! for (int n=threadIdx.x; n<ind_arg2_size*1; n+=blockDim.x)
			!		ind_arg2_s[n] = ind_arg2[n%1+ind_arg2_map[n/1]*1];
			n = (threadidx%x-1)
			whileBound = ind_arg2_size * 1
			do while ( n .lt. whileBound )
				! nbytes = 0 => 0 + ..
				moduled = mod ( n, 1 )

				! remember that:
				!				ind_arg2_map = ind_arg2_maps + ind_arg_offs[2+blockId*4];
				! and:
				!				nbytes    += ROUND_UP(ind_arg1_size*sizeof(double)*4); == nbytes2
				!				ind_arg2_s = (double *) &shared[nbytes];
				myshared(nbytes2 + n) = pindArg2(moduled  + ( pindArg2Maps ( 0 + pindArgOffs( 2 + blockId * 4 ) + ( n / 1 ) ) ) * 1)
				
				n = n + (blockdim%x)
			end do									           

			! implements:																																									                                                                                 
			! for (int n=threadIdx.x; n<ind_arg3_size*4; n+=blockDim.x)
			!		ind_arg3_s[n] = ZERO_float;                       
			n = (threadidx%x-1)
			whileBound = ind_arg3_size * 4
			do while ( n .lt. whileBound )
				! nbytes = 0 => 0 + ..
				!moduled = mod ( n, 2 )

				! remember that:
				!				ind_arg3_map = ind_arg3_maps + ind_arg_offs[3+blockId*4];
				! and:
				!				nbytes    += ROUND_UP(ind_arg2_size*sizeof(double)*1); == nbytes2
				!				ind_arg3_s = (double *) &shared[nbytes];
				myshared(nbytes3 + n) = 0
				
				n = n + (blockdim%x)
			end do

			! make sure all of above completed
			call syncthreads()
!
			! for (int n=threadIdx.x; n<nelems2; n+=blockDim.x) {
			! process set elements
			n = (threadidx%x-1)
			do while ( n .lt. nelems2 )
				
				col2 = -1
				
				if ( n < nelem ) then
					
					! initialise local variables
					do iterInit = 0, 3
						arg6_l(iterInit) = 0
					end do

					do iterInit = 0, 3
						arg7_l(iterInit) = 0
					end do
					
					! call user kernel
					
					! ind_arg0_s+arg0_maps[n+offset_b]*2
					! ind_arg0_s+arg1_maps[n+offset_b]*2
					! ind_arg1_s+arg2_maps[n+offset_b]*4
					! ind_arg1_s+arg3_maps[n+offset_b]*4
					! ind_arg2_s+arg4_maps[n+offset_b]*1,
					! ind_arg2_s+arg5_maps[n+offset_b]*1,
					call res_calc ( myshared ( nbytes0 + parg0Maps (n + offset_b) * 2 : (nbytes0 + parg0Maps(n + offset_b) * 2) + 2 ), &
													myshared ( nbytes0 + parg1Maps (n + offset_b) * 2 : (nbytes0 + parg1Maps(n + offset_b) * 2) + 2 ), &
													myshared ( nbytes1 + parg2Maps (n + offset_b) * 4 : (nbytes1 + parg2Maps(n + offset_b) * 4) + 4 ), &
													myshared ( nbytes1 + parg3Maps (n + offset_b) * 4 : (nbytes1 + parg3Maps(n + offset_b) * 4) + 4 ), &
													myshared ( nbytes2 + parg4Maps (n + offset_b) * 1 : (nbytes2 + parg4Maps(n + offset_b) * 1) + 1 ), &
													myshared ( nbytes2 + parg5Maps (n + offset_b) * 1 : (nbytes2 + parg5Maps(n + offset_b) * 1) + 1 ), &
													arg6_l, &
													arg7_l &
												)	
													
					! col2 = colors[n+offset_b];
					col2 = pcolors(n + offset_b )
					
				end if
				
				! int arg6_map = arg6_maps[n+offset_b];                                         
				! int arg7_map = arg7_maps[n+offset_b];                                         
				arg6_map = parg6Maps ( n + offset_b )
				arg7_map = parg7Maps ( n + offset_b )
				
				! for (int col=0; col<ncolor; col++) {                                          
				do col = 0, ncolor-1
				
					if ( col2 .eq. col ) then
										
						! for (int d=0; d<4; d++)
						do iterInit = 0, 3
						  ! ind_arg3_s[d+arg6_map*4] += arg6_l[d];
							myshared(nbytes3 + iterInit + arg6_map*4 ) = myshared(nbytes3 + iterInit + arg6_map*4 ) + arg6_l(iterInit)
						end do

						! for (int d=0; d<4; d++)
						do iterInit = 0, 3
						  ! ind_arg3_s[d+arg7_map*4] += arg7_l[d];
							myshared(nbytes3 + iterInit + arg7_map*4 ) = myshared(nbytes3 + iterInit + arg7_map*4 ) + arg7_l(iterInit)
						end do
					
					end if
					
					! make sure all of above completed
					call syncthreads()
				
				end do
				
				n = n + (blockdim%x)
			end do	
			
			! apply pointered write/increment
                                                                                  
			! for (int n=threadIdx.x; n<ind_arg3_size*4; n+=blockDim.x)
			!		ind_arg3[n%4+ind_arg3_map[n/4]*4] += ind_arg3_s[n];
			n = (threadidx%x-1)
			do while ( n < ind_arg3_size*4 )
				
				moduled = mod ( n, 4 )
				
				! remember that:
				! ind_arg3_map = ind_arg3_maps + ind_arg_offs[3+blockId*4];
				! and that:
				! ind_arg3_s = myshared(nbytes3)
				pindArg3 ( moduled + pindArg3Maps ( (0 + pindArgOffs ( 3 + blockId * 4 )) + (n / 4) ) * 4 ) = pindArg3 ( moduled + pindArg3Maps ( (0 + pindArgOffs ( 3 + blockId * 4 )) + (n / 4) ) * 4 ) + myshared(nbytes3 + n)
				
				n = n + (blockdim%x)
			end do
			                                         
		end subroutine op_cuda_res_calc              

		attributes(host) function op_par_loop_res_calc ( subroutineName, set, &
																										 & arg0,   idx0, map0, access0, &
																										 & arg1,   idx1, map1, access1, &
																										 & arg2,   idx2, map2, access2, &
																										 & arg3,   idx3, map3, access3, &
																										 & arg4,   idx4, map4, access4, &
																										 & arg5,   idx5, map5, access5, &
																										 & arg6,   idx6, map6, access6, &
																										 & arg7,   idx7, map7, access7  &
																									 & )

		! use directives	
		use, intrinsic :: ISO_C_BINDING
		use cudafor

		! mandatory	
		implicit none
		
		type(profInfo) :: op_par_loop_res_calc
		
		! formal arguments
		character(kind=c_char,len=*), intent(in) :: subroutineName
		
		! data set on which we loop
		type(op_set), intent(in) :: set

		! data ids used in the function
		type(op_dat) :: arg0, arg1, arg2, arg3, arg4, arg5, arg6, arg7
		
		! index to be used in first and second pointers
		integer(4), intent(in) :: idx0, idx1, idx2, idx3, idx4, idx5, idx6, idx7
		
		! ptr ids for indirect access to data
		type(op_map) :: map0, map1, map2, map3, map4, map5, map6, map7
		
		! access values for arguments
		integer(4), intent(in) :: access0, access1, access2, access3, access4, access5, access6, access7

		! Compiler: variables used to invoke cplan 
		integer(4) :: args(8), idxs(8), maps(8), accs(8), inds(8)
		integer(4) :: argsNumber, indsNumber

!		! returned plan address by cplan and plan functions
!		type(c_ptr) :: planRet
!		
!		! variable for storing the actual OP Plan
		type(op_plan), pointer :: actualPlan
			
		! iteration and offset variables to implement plan execution
		integer(4) :: blockOffset, col

		! configuration variables for main kernel call
		integer(4) :: nblocks, nthread, nshared
		
		! iteration variables
		integer(4) :: i, m, iter

		! value returned by thread synchronisation function
		integer(4) :: threadsynchret
		
		! Fortran variable for Host variable
		integer, pointer, dimension(:) :: ncolblk
!		
		integer, pointer, dimension(:) :: pnindirect
!		
!		
!		! ind_maps is an array of device pointers allocated on the host memory
		type(c_devptr), pointer, dimension(:) :: pindMaps
		integer(4), dimension(1) :: pindMapsSize
!								
!		! as many pindMapsI as the positions of pindMaps (4 in this case = indsNumber )
		integer, allocatable, device, dimension(:) :: pindMaps1
		integer(4) :: pindMaps1Size
!
		integer, allocatable, device, dimension(:) :: pindMaps2
		integer(4) :: pindMaps2Size
!
		integer, allocatable, device, dimension(:) :: pindMaps3
		integer(4) :: pindMaps3Size
!
		integer, allocatable, device, dimension(:) :: pindMaps4
		integer(4) :: pindMaps4Size
!
!		! maps is an array of device pointers allocated on the host memory
		type(c_devptr), pointer, dimension(:) :: pmaps
		integer(4), dimension(6) :: pmapsSize ! dimension = argsNumber (= 6, see below)
!
!		! as many pMapsI as the positions of pmaps (8 for this case) (they are short integers)
		integer(2), allocatable, device, dimension(:) :: pMaps1
		integer(2), allocatable, device, dimension(:) :: pMaps2
		integer(2), allocatable, device, dimension(:) :: pMaps3
		integer(2), allocatable, device, dimension(:) :: pMaps4
		integer(2), allocatable, device, dimension(:) :: pMaps5
		integer(2), allocatable, device, dimension(:) :: pMaps6
		integer(2), allocatable, device, dimension(:) :: pMaps7
		integer(2), allocatable, device, dimension(:) :: pMaps8
!
		integer(4) :: pmaps1Size, pmaps2Size, pmaps3Size, pmaps4Size, pmaps5Size, pmaps6Size, pmaps7Size, pmaps8Size
!
		integer, device, allocatable, dimension(:) :: pindSizes
		integer(4) :: pindSizesSize
!		
		integer, device, allocatable, dimension(:) :: pindOffs
		integer(4) :: pindOffsSize
!		
		integer, device, allocatable, dimension(:) :: pblkMap
		integer(4) :: pblkMapSize
!		
		integer, device, allocatable, dimension(:) :: poffset
		integer(4) :: poffsetSize
!		
		integer, device, allocatable, dimension(:) :: pnelems
		integer(4) :: pnelemsSize
!		
		integer, device, allocatable, dimension(:) :: pnthrcol
		integer(4) :: pnthrcolSize
!		
		integer, device, allocatable, dimension(:) :: pthrcol
		integer(4) :: pthrcolSize

		! variables for marshalling data from host to device memory and back
!		integer(4) :: arg0Size, arg2Size, arg4Size, arg6Size
!
		real(8), dimension(:), allocatable, device :: argument0
		real(8), dimension(:), allocatable, device :: argument2
		real(8), dimension(:), allocatable, device :: argument4
		real(8), dimension(:), allocatable, device :: argument6
!		
!		! sizes of variables passed to kernel are all encapsulated inside a single struct
!		type(varSizes_res_calc), device :: argSizes
		
		! profiling
		integer :: istat
		type (cudaEvent) :: startKernelTime, stopKernelTime, startHostTime, stopHostTime
		real(4) :: tmpHostTime

		! create events
		istat = cudaEventCreate(startKernelTime)
		istat = cudaEventCreate(stopKernelTime)
		istat = cudaEventCreate(startHostTime)
		istat = cudaEventCreate(stopHostTime)
		
		istat = cudaEventRecord ( startHostTime, 0 )

		
		! stage in of input arguments (transfer pointers + copy from host to device memory)
		
		if ( isKernelInputDataGenerated .eq. .false. ) then 
		
!			isKernelInputDataGenerated = .true.
		
			! filling up variables for building the plan
			args(1) = arg0%index
			args(2) = arg1%index
			args(3) = arg2%index
			args(4) = arg3%index
			args(5) = arg4%index
			args(6) = arg5%index
			args(7) = arg6%index
			args(8) = arg7%index
		
			idxs(1) = idx0
			idxs(2) = idx1
			idxs(3) = idx2
			idxs(4) = idx3
			idxs(5) = idx4
			idxs(6) = idx5
			idxs(7) = idx6
			idxs(8) = idx7
			
			! when passing from OP2 Fortran to OP2 C++ we have to decrement the idx values (not 1->N, but 0->N-1)
			! except -1 which indicates OP_ID or OP_GBL
			do iter = 1, 8
				if ( idxs(iter) /= -1 ) idxs(iter) = idxs(iter) - 1 
			end do

			maps(1) = map0%index
			maps(2) = map1%index
			maps(3) = map2%index
			maps(4) = map3%index
			maps(5) = map4%index
			maps(6) = map5%index
			maps(7) = map6%index
			maps(8) = map7%index

			accs(1) = access0
			accs(2) = access1
			accs(3) = access2
			accs(4) = access3
			accs(5) = access4
			accs(6) = access5
			accs(7) = access6
			accs(8) = access7		


			! Compiler: generate this information by analysing the arguments
			argsNumber = 8
			indsNumber = 4 ! warning: this means the number of op_dat accessed indirectly, not the number of arguments!!
		
			inds(1) = 0
			inds(2) = 0
			inds(3) = 1
			inds(4) = 1
			inds(5) = 2
			inds(6) = 2
			inds(7) = 3
			inds(8) = 3

			! get the plan
			planRet = cplan ( subroutineName, set%index, argsNumber, args, idxs, maps, accs, indsNumber, inds )  		

			call res_calc_initialiseConstants()

		end if

			! 1. transfer C pointers to Fortran pointers
			arg0Size = arg0%dim * arg0%set%size
			call c_f_pointer ( arg0%dat_d, argument0, (/arg0Size/) )


			arg2Size = arg2%dim * arg2%set%size
			call c_f_pointer ( arg2%dat_d, argument2, (/arg2Size/) )

			arg4Size = arg4%dim * arg4%set%size
			call c_f_pointer ( arg4%dat_d, argument4, (/arg4Size/) )
			
			arg6Size = arg6%dim * arg6%set%size
			call c_f_pointer ( arg6%dat_d, argument6, (/arg6Size/) )


			! convert arguments and plan data to Fortran pointers (not a copy!)
			! Typically, first compute size, then transform pointer
			
			! transform the returned C pointer to a type(op_plan) variable
			call c_f_pointer ( planRet, actualPlan )		
			
			! convert nindirect  used to generate the pindMapsSize array of sizes
			call c_f_pointer ( actualPlan%nindirect, pnindirect, (/indsNumber/) )
				
			! convert pindMaps: there are indsNumber ind_maps
			call c_f_pointer ( actualPlan%ind_maps, pindMaps, (/indsNumber/) )
			
			! convert first position of the pindMaps array (the size is stored in the corresponding pnindirect position)
			call c_f_pointer ( pindMaps(1), pindMaps1, pnindirect(1) )
			call c_f_pointer ( pindMaps(2), pindMaps2, pnindirect(2) )
			call c_f_pointer ( pindMaps(3), pindMaps3, pnindirect(3) )
			call c_f_pointer ( pindMaps(4), pindMaps4, pnindirect(4) )
					
			! must be done for all indirect pointers: in this case 4 different arguments are accessed indirectly
			
			! convert maps in op_plan: there are argsNumber maps
			call c_f_pointer ( actualPlan%maps, pmaps, (/argsNumber/) )
			
			! convert positions in pmaps (only if the corresponding inds position is >= 0 (see op_support.cpp))
			! can't do a do-loop because I can't generate variable name
			if ( inds(1) .ge. 0 ) then
				pmaps1Size = set%size
				call c_f_pointer ( pmaps(1), pmaps1, (/pmaps1Size/) )
			end if
			
			if ( inds(2) .ge. 0 ) then
				pmaps2Size = set%size
				call c_f_pointer ( pmaps(2), pmaps2, (/pmaps2Size/) )
			end if
			
			if ( inds(3) .ge. 0 ) then
				pmaps3Size = set%size
				call c_f_pointer ( pmaps(3), pmaps3, (/pmaps3Size/) )
			end if
			
			if ( inds(4) .ge. 0 ) then
				pmaps4Size = set%size
				call c_f_pointer ( pmaps(4), pmaps4, (/pmaps4Size/) )
			end if
			
			if ( inds(5) .ge. 0 ) then
				pmaps5Size = set%size
				call c_f_pointer ( pmaps(5), pmaps5, (/pmaps5Size/) )
			end if
			
			if ( inds(6) .ge. 0 ) then
				pmaps6Size = set%size
				call c_f_pointer ( pmaps(6), pmaps6, (/pmaps6Size/) )
			end if	
			
			if ( inds(7) .ge. 0 ) then
				pmaps7Size = set%size
				call c_f_pointer ( pmaps(7), pmaps7, (/pmaps7Size/) )
			end if	

			if ( inds(8) .ge. 0 ) then
				pmaps8Size = set%size
				call c_f_pointer ( pmaps(8), pmaps8, (/pmaps8Size/) )
			end if
			
			! converting ncolblk field to fortran variable
			call c_f_pointer ( actualPlan%ncolblk, ncolblk, (/set%size/) )
			
			! ind_sizes field has nblocks*indsNumber size
			pindSizesSize = actualPlan%nblocks * indsNumber
			call c_f_pointer ( actualPlan%ind_sizes, pindSizes, (/pindSizesSize/) )
				
			! ind_offset field has the same dimension of ind_sizes
			pindOffsSize = pindSizesSize
			call c_f_pointer ( actualPlan%ind_offs, pindOffs, (/pindOffsSize/) )
				
			! blkmap field has dimension nblocks
			pblkMapSize = actualPlan%nblocks
			call c_f_pointer ( actualPlan%blkmap, pblkMap, (/pblkMapSize/) )
				
			! offset field has dimension nblocks
			poffsetSize = actualPlan%nblocks
			call c_f_pointer ( actualPlan%offset, poffset, (/poffsetSize/) )
			
			! nelems field has dimension nblocks
			pnelemsSize = actualPlan%nblocks
			call c_f_pointer ( actualPlan%nelems, pnelems, (/pnelemsSize/) )

			! nthrcol field has dimension nblocks
			pnthrcolSize = actualPlan%nblocks
			call c_f_pointer ( actualPlan%nthrcol, pnthrcol, (/pnthrcolSize/) )
			
			! thrcol field has dimension set%size
			pthrcolSize = set%size
			call c_f_pointer ( actualPlan%thrcol, pthrcol, (/pthrcolSize/) )

			blockOffset = 0

		if ( isKernelInputDataGenerated .eq. .false. ) then 
		
			isKernelInputDataGenerated = .true.


			! sizes are compacted in a single struct, to save parameter space
			argSizes%pindArg0Size = arg0Size
			argSizes%pindArg0MapsSize = pnindirect(1)
			argSizes%pindArg1Size = arg2Size
			argSizes%pindArg1MapsSize = pnindirect(2)
			argSizes%pindArg2Size = arg4Size
			argSizes%pindArg2MapsSize = pnindirect(3)
			argSizes%pindArg3Size = arg6Size
			argSizes%pindArg3MapsSize = pnindirect(4)
			argSizes%parg0MapsSize = pMaps1Size
			argSizes%parg1MapsSize = pMaps2Size
			argSizes%parg2MapsSize = pMaps3Size
			argSizes%parg3MapsSize = pMaps4Size
			argSizes%parg4MapsSize = pMaps5Size
			argSizes%parg5MapsSize = pMaps6Size
			argSizes%parg6MapsSize = pMaps7Size
			argSizes%parg7MapsSize = pMaps8Size
			argSizes%pindArgSizesSize = pindSizesSize
			argSizes%pindArgOffsSize = pindOffsSize
			argSizes%pblkMapSize = pblkMapSize
			argSizes%pOffsetSize = poffsetSize
			argSizes%pNelemsSize = pnelemsSize
			argSizes%pNcolorsSize = pnthrcolSize
			argSizes%pColorsSize = pthrcolSize

		end if

		istat = cudaEventRecord ( stopHostTime, 0 )
		istat = cudaEventSynchronize ( stopHostTime )
		istat = cudaEventElapsedTime ( tmpHostTime, startHostTime, stopHostTime )

		op_par_loop_res_calc%hostTime = 0
		op_par_loop_res_calc%hostTime = op_par_loop_res_calc%hostTime + tmpHostTime
		tmpHostTime = 0



	  istat = cudaEventRecord ( startKernelTime, 0 )
		
		! execute the plan
		do col = 0, (actualPlan%ncolors-1)
			
			nblocks = ncolblk(col+1) !+1 is needed because ncolblk is indexed from 1:set%size and not from 0:set%size-1
			nthread = FOP_BLOCK_SIZE
			nshared = actualPlan%nshared

!			print *, 'col = ', col, nblocks, nthread, nshared

			! call the main kernel (I need to add the variable sizes, otherwise we would get sigsegv in copy back)
			call op_cuda_res_calc <<< nblocks, nthread, nshared >>> ( argSizes, &
																																argument0, pindMaps1, &
																																argument2, pindMaps2, &
																																argument4, pindMaps3, &
																																argument6, pindMaps4, &
																																pMaps1, &
																																pMaps2, &
																																pMaps3, &
																																pMaps4, &
																																pMaps5, &
																																pMaps6, &
																																pMaps7, &
																																pMaps8, &
																																pindSizes, &
																																pindOffs, &
																																blockOffset, &
																																pblkMap, &
																																poffset, &
																																pnelems, &
																																pnthrcol, &
																																pthrcol &
																															)
																																
			! wait for the threads on device to terminate execution
			threadSynchRet = cudaThreadSynchronize()
		
			blockOffset = blockOffset + nblocks
		
		end do


		istat = cudaEventRecord ( stopKernelTime, 0 )
		istat = cudaEventSynchronize ( stopKernelTime )
		istat = cudaEventElapsedTime ( op_par_loop_res_calc%kernelTime, startKernelTime, stopKernelTime )

		istat = cudaEventRecord ( startHostTime, 0 )
		istat = cudaEventRecord ( stopHostTime, 0 )
		istat = cudaEventSynchronize ( stopHostTime )
		istat = cudaEventElapsedTime ( tmpHostTime, startHostTime, stopHostTime )

		op_par_loop_res_calc%hostTime = op_par_loop_res_calc%hostTime + tmpHostTime

	end function op_par_loop_res_calc

end module res_calc_cuda_module
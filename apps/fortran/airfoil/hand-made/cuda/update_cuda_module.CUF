
module update_cuda_module

	use OP2_C
	use cudaConfigurationParams
!	use constantVarsCuda
	use OP2Profiling
	use cudafor

	type varSizes_update

		integer(4) :: parg0Size
		integer(4) :: parg1Size
		integer(4) :: parg2Size
		integer(4) :: parg3Size
		integer(4) :: parg4Size
	
	end type varSizes_update

	! debug
	logical :: firstTimeCalled = .true.
	
	! logical that tells if the input data to the kernel has been already generated
	! by previous calls to this same op_par_loop function
	logical :: isKernelInputDataGenerated = .false.

	type(varSizes_update), device :: argSizes
	
	integer(4) :: arg0Size, arg1Size, arg2Size, arg3Size, arg4Size

!	real(8), dimension(:), allocatable, device :: argument0
!	real(8), dimension(:), allocatable, device :: argument1
!	real(8), dimension(:), allocatable, device :: argument2
!	real(8), dimension(:), allocatable, device :: argument3
!	real(8), dimension(:), allocatable, device :: argument4

	real(8), dimension(:), pointer :: c2fPtrArg4

	
contains
	
	! implements global tree reduction for OP_INC only
	attributes(device) subroutine reduct_update ( dat_g, dat_l, wsize, startOffset )

		use cudafor

		implicit none

		real(8), dimension(1), device :: dat_g
		real(8), value :: dat_l

		! this is the value of warpsize, passed from the caller because I can't use it here
		! (I don't know why, the compiler returns an internal error)
		integer, value :: wsize

		! This is the starting offset in the automatically allocated shared variable.
		! The space following this index is reserved for use to this reduction routine
		integer(4), value :: startOffset

		real(8), dimension(0:*), shared :: temp
		integer(4) :: tid

		integer(4) :: d
		
		! must convert the starting offset from byte to real(8) element addressing
		startOffset = startOffset / 8
		
		! the size can be precomputed without the need of automatically allocate it				
		tid = ( threadidx%x - 1 )

		! the following is a right shift of 1 bit
		d = ishft ( blockdim%x, -1 )
		
		call syncthreads()

		temp(startOffset + tid) = dat_l
		
		! implements:
		! for (; d>warpSize; d>>=1) {
		do while ( d .gt. 0 )
		
			call syncthreads()

			if ( tid .lt. d ) then
				! in this case it just implements OP_INC
				temp(startOffset + tid ) = temp(startOffset + tid ) + temp(startOffset + (tid + d) )
			end if

!			d = d / 2
			
			d = ishft ( d, -1 )
		end do

		call syncthreads()
		
		! the first thread in each block terminates the local reduction
		if ( tid .eq. 0 ) then

			! in this case it just implements OP_INC
			dat_g(1) = dat_g(1) + temp(startOffset)
		
		end if

		call syncthreads()

	end subroutine reduct_update
	
	
	attributes(device) subroutine update ( qold, q, res, adt, rms )

		implicit none

		! formal parameters
		real(8), dimension(4) :: qold
		real(8), dimension(4) :: q
		real(8), dimension(4) :: res
		real(8), dimension(1) :: adt
		real(8), dimension(1) :: rms
		
		real(8) :: del, adti

		integer(4) :: i

		adti = 1.0 / adt(1)

		do i = 1, 4
			del = adti * res(i)
			q(i) = qold(i) - del
			res(i) = 0.0
			rms(1) = rms(1) + del * del
		end do

	end subroutine update
	
	attributes(global) subroutine op_cuda_update ( argSizes, &
																							 & parg0, &
																							 & parg1, &
																							 & parg2, &
																							 & parg3, &
																							 & parg4, &
																							 & offsetS, &
																							 & setSize, &
																							 & warpSizeOP2, &
																							 & redStartOffset &
																						 & )
	
		use cudafor
	
		implicit none

		type(varSizes_update), device :: argSizes

		real(8), dimension(0:(argSizes%parg0Size)-1), device :: parg0
		real(8), dimension(0:(argSizes%parg1Size)-1), device :: parg1
		real(8), dimension(0:(argSizes%parg2Size)-1), device :: parg2
		real(8), dimension(0:(argSizes%parg3Size)-1), device :: parg3
		real(8), dimension(0:(argSizes%parg4Size)-1), device :: parg4
		
		
		integer(4), value :: offsetS
		integer(4), value :: setSize
		integer(4), value :: warpSizeOP2
		
		! the following is the starting position in the automatically allocated shared memory
		! reserved for using by the reduction routine
		integer(4), value :: redStartOffset
		
		real(8), dimension(0:3) :: arg0_l
		real(8), dimension(0:3) :: arg1_l
		real(8), dimension(0:3) :: arg2_l
		real(8), dimension(0:0) :: arg4_l

		! iteration variables
		integer(4) :: d, n, m
		integer(4) :: tid, offset, nelems, outof
		
		! debug
!		integer(4) :: outofbound = 0

		
		! automatic shared memory
		real(8), shared :: autoshared(0:*)
		
		! remember from now on that:
		! char *arg_s = shared + offset_s*(threadIdx.x/OP_WARPSIZE);
		integer(4) :: argSDisplacement
				
		! the displacement must be given in terms of real(8) elements, and not shared variables
		argSDisplacement = (offsetS * ( (threadidx%x-1) / warpSizeOP2 )) / 8
		
		do d = 0, 0
		
			arg4_l(d) = 0
		
		end do
		
		! implements:
		! int   tid = threadIdx.x%OP_WARPSIZE;
		tid = mod ( (threadidx%x)-1, warpSizeOP2 )

		! process set elements

		!	implements:
		! for (int n=threadIdx.x+blockIdx.x*blockDim.x;
    !			 n<set_size; n+=blockDim.x*gridDim.x) {
		n = (threadidx%x-1) + (blockidx%x-1) * blockdim%x
		do while ( n .lt. setSize )
		
			offset = n - tid
			
			nelems = min ( warpSizeOP2, (setSize - offset) )
			
			! copy data into shared memory, then into local
			
			! implements:
			! for (int m=0; m<4; m++)
      !		((double *)arg_s)[tid+m*nelems] = arg0[tid+m*nelems+offset*4];
			do m = 0, 3
			
				! autoshared ( argSDisplacement ) = arg_s
				! 4 is the dimension of argument 0 in this op_par_loop call ! argSDisplacement
				autoshared ( argSDisplacement  + ( tid + m * nelems ) ) = parg0 ( tid + m * nelems + offset * 4 )
						
			end do
                                 
			! implements:
			! for (int m=0; m<4; m++)
      !		arg0_l[m] = ((double *)arg_s)[m+tid*4];
			do m = 0, 3
			
				! autoshared ( argSDisplacement ) = arg_s
				! 4 is the dimension of argument 0 in this op_par_loop call
				arg0_l(m) = autoshared ( argSDisplacement + ( m + tid * 4 ) )
			
			end do

			! implements:
			! for (int m=0; m<4; m++)
			!		((double *)arg_s)[tid+m*nelems] = arg2[tid+m*nelems+offset*4];
			do m = 0, 3
			
				! autoshared ( argSDisplacement ) = arg_s
				! 4 is the dimension of argument 0 in this op_par_loop call
				autoshared ( argSDisplacement + ( tid + m * nelems ) ) = parg2 ( tid + m * nelems + offset * 4 )
			
			end do

			! implements:
			! for (int m=0; m<4; m++)
			!		arg2_l[m] = ((double *)arg_s)[m+tid*4];
			do m = 0, 3
			
				! autoshared ( argSDisplacement ) = arg_s
				! 4 is the dimension of argument 0 in this op_par_loop call
				arg2_l(m) = autoshared ( argSDisplacement + ( m + tid * 4 ) )
			
			end do


			! user-supplied kernel call
			
			! implements:
	    ! update( arg0_l,
			!					arg1_l,
			!					arg2_l,
			!					arg3+n,
			!					arg4_l );
			
			call update ( arg0_l, &
									& arg1_l, &
									& arg2_l, &
									& parg3 ( n : n ), &
									& arg4_l  &
								&	)

			
			! copy back into shared memory, then to device
			
			! implements:
			! for (int m=0; m<4; m++)
      !		((double *)arg_s)[m+tid*4] = arg1_l[m];
			do m = 0, 3
			
				! autoshared ( argSDisplacement ) = arg_s
				! 4 is the dimension of argument 0 in this op_par_loop call
				autoshared ( argSDisplacement + ( m + tid * 4 ) ) = arg1_l(m)
							
			end do

			
			! implements:
			! for (int m=0; m<4; m++)
      !		arg1[tid+m*nelems+offset*4] = ((double *)arg_s)[tid+m*nelems];
			do m = 0, 3
			
				! autoshared ( argSDisplacement ) = arg_s
				! 4 is the dimension of argument 0 in this op_par_loop call
				parg1 ( tid + m * nelems + offset * 4 ) = autoshared ( argSDisplacement + ( tid + m * nelems ) )
			
			end do
                                                                                  
			! implements:
			! for (int m=0; m<4; m++)
      !		((double *)arg_s)[m+tid*4] = arg2_l[m];
			do m = 0, 3
			
				! autoshared ( argSDisplacement ) = arg_s
				! 4 is the dimension of argument 0 in this op_par_loop call
				autoshared ( argSDisplacement + ( m + tid * 4 ) ) = arg2_l(m)
			
			end do

			
			! implements:
			! for (int m=0; m<4; m++)
      !		arg2[tid+m*nelems+offset*4] = ((double *)arg_s)[tid+m*nelems];
			do m = 0, 3
			
				! autoshared ( argSDisplacement ) = arg_s
				! 4 is the dimension of argument 0 in this op_par_loop call
				parg2 ( tid + m * nelems + offset * 4 ) = autoshared ( argSDisplacement + ( tid + m * nelems ) )
			
			end do
			
			n = n + blockdim%x * griddim%x
		
		end do

		! global reductions
		
		! implements:
		! for(int d=0; d<1; d++) op_reduction<OP_INC>(&arg4[d+blockIdx.x*1],arg4_l[d]);
		
		
		
		do d = 0, 0
		
			call reduct_update ( parg4 ( d + (blockidx%x -1) * 1 : d + (blockidx%x -1) * 1 ), arg4_l(d), warpSizeOP2, redStartOffset )
		
		end do
		
!		if ( outof .eq. -1 ) then
!
!			parg4 ( 0 + (blockidx%x -1) * 1 ) = -100.0
!		
!		else
!		
!			parg4 ( 0 + (blockidx%x -1) * 1 ) = -200.0
!			
!		end if
		
		
	end subroutine op_cuda_update

!	attributes(host) function round_up ( intval )
!	
!		integer(4) :: intval
!		
!		integer(4) :: round_up
!		
!		round_up = iand ( ( intval ) + 15, not ( 15 ) )
!	
!	end function round_up

	attributes(host) function op_par_loop_update ( subroutineName, set, &
																								 & arg0,   idx0, map0, access0, &
																								 & arg1,   idx1, map1, access1, &
																								 & arg2,   idx2, map2, access2, &
																								 & arg3,   idx3, map3, access3, &
																								 & arg4,   idx4, map4, access4  &
																							 & )

		use cudafor

		implicit none
		
		type(profInfo) :: op_par_loop_update
		
		! formal arguments
		character(kind=c_char,len=*), intent(in) :: subroutineName
		
		! data set on which we loop
		type(op_set), intent(in) :: set

		! data ids used in the function
		type(op_dat) :: arg0, arg1, arg2, arg3, arg4
		
		! index to be used in first and second pointers
		integer(4), intent(in) :: idx0, idx1, idx2, idx3, idx4
		
		! ptr ids for indirect access to data
		type(op_map) :: map0, map1, map2, map3, map4
		
		! access values for arguments
		integer(4), intent(in) :: access0, access1, access2, access3, access4

		! set CUDA execution parameters
		integer(4) :: nblocks = 200
		integer(4) :: nthreads = 128

		! transfer global reduction data to GPU
		integer(4) :: maxblocks 
		integer(4) :: reductItems = 0
		integer(4) :: reductSize = 0
		
		! these two variables implement the global reduction in the host and device memory, respectively
		! and they contain the values computed by each thread block
		real(8), dimension(:), allocatable :: redArrayHost
		real(8), dimension(:), allocatable, device :: redArrayDev
		
!		integer(4) :: arg0Size, arg1Size, arg2Size, arg3Size, arg4Size
!		real(8), dimension(:), pointer :: c2fPtrArg4

		real(8), dimension(:), allocatable, device :: argument0
		real(8), dimension(:), allocatable, device :: argument1
		real(8), dimension(:), allocatable, device :: argument2
		real(8), dimension(:), allocatable, device :: argument3
		real(8), dimension(:), allocatable, device :: argument4
		
		! this is needed to avoid having more than 1 device variable in the same expression (see re-assignement
		! after kernel call below)
		real(8) :: partialArg4Sum = 0
		real(8) :: partialRedArrayDev4Sum = 0
		
		! iteration variables
		integer(4) :: i, b, d

		! CUDA configuration variables and related stuff 
		integer(4) :: nshared
		integer(4) :: offsetS
		integer(4) :: warpSizeOP2
		integer(4) :: maxReductionSize
		integer(4) :: redStartOffset

		! value returned by thread synchronisation function
		integer(4) :: threadsynchret

		! size of arguments
!		type(varSizes_update), device :: argSizes

		real(8) :: reductedValue = 0

		integer(4) :: retDebug
		real(8) :: datad, summed

		! profiling
		integer :: istat
		type (cudaEvent) :: startKernelTime, stopKernelTime, startHostTime, stopHostTime
		real(4) :: tmpHostTime

		! create events
		istat = cudaEventCreate(startKernelTime)
		istat = cudaEventCreate(stopKernelTime)
		istat = cudaEventCreate(startHostTime)
		istat = cudaEventCreate(stopHostTime)
		
		istat = cudaEventRecord ( startHostTime, 0 )


		warpSizeOP2 = OP_WARP_SIZE
		
		maxblocks = nblocks
		
		! 1 is the size of p_rms and 8 is the size of its type (real(8))
		! Mike's version is : reductBytes + round_up ( maxblocks * 1 * 8 )
		
		reductItems = maxblocks * 1 ! 1 is the dimension of the global data

		reductSize = max ( reductSize, 8 )
				
		allocate ( redArrayDev ( reductItems ) )


		if ( isKernelInputDataGenerated .eq. .false. ) then
		
			isKernelInputDataGenerated = .true.
		
			! allocate reduction arrays on host and device memory
!			allocate ( redArrayHost ( reductItems ) )


			! setting up arguments sizes
			argSizes%parg0Size = arg0Size
			argSizes%parg1Size = arg1Size
			argSizes%parg2Size = arg2Size
			argSizes%parg3Size = arg3Size

			! the size of the last argument is different from the one of the global data (arg4),
			! because we instatiate a copy of that global data on device memory for each thread used
			argSizes%parg4Size = reductItems

		end if

			
			! remember that:
			! arg4.dat   = OP_reduct_h + reduct_bytes;
			! arg4.dat_d = OP_reduct_d + reduct_bytes;
			
			! copy reduction array from host to device
!			redArrayDev = redArrayHost
			
			! work out shared memory requirements per element (this is mandatory, otherwise the default value is the
			! one that has been assigned as a result of the previous execution of this op_par_loop)
			nshared = 0

			! this should be done for each op_dat argument copied to shared memory
			! in this case the three of them have dim = 4 and it is actually useless
			nshared = max ( nshared, 8 * 4 ) ! 8 = sizeof(double) => real(8)
			nshared = max ( nshared, 8 * 4 ) ! 8 = sizeof(double) => real(8)
			nshared = max ( nshared, 8 * 4 ) ! 8 = sizeof(double) => real(8)

			offsetS = nshared * OP_WARP_SIZE

			! in Fortran the reduction variable is merged in the same automatically allocated
			! shared variable, and the size is: the size of the needed memory for the 
			! arguments *plus* the size of the needed memory for the reduction variable (see below)
			nshared = nshared * nthreads

	!		nshared = max ( nshared * nthreads, reductSize * nthreads )
			
			! copy arguments from host to device

			! 1. transfer C pointers to Fortran pointers
			arg0Size = arg0%dim * arg0%set%size
			call c_f_pointer ( arg0%dat_d, argument0, (/arg0Size/) )

			arg1Size = arg1%dim * arg1%set%size
			call c_f_pointer ( arg1%dat_d, argument1, (/arg1Size/) )
			
			arg2Size = arg2%dim * arg2%set%size
			call c_f_pointer ( arg2%dat_d, argument2, (/arg2Size/) )
			
			arg3Size = arg3%dim * arg3%set%size
			call c_f_pointer ( arg3%dat_d, argument3, (/arg3Size/) )
			
			! warning: the argument is a global op_dat so the size is directly the dim of the op_dat
			arg4Size = arg4%dim
			call c_f_pointer ( arg4%dat, c2fPtrArg4, (/arg4Size/) )





			! in Fortran CUDA we have to allocate enough automatic shared memory
			! directly from here, and to fit all information in the "same space:
			! (see the difference between Fortran CUDA automatic shared variables
			! and C CUDA ones)

			! the start offset of dynamically allocated shared memory is the end of the previously
			! allocated shared space used for some of the parallel loop variables
			redStartOffset = nshared

			! Adding up memory space for shared variable in reduction routine
			! (this is actually the max addressable position in the reduction variable)
			maxReductionSize = nthreads * 8 !( nthreads - 1 ) +  ishft ( nblocks, -1 ) * reductSize 
			nshared = nshared + maxReductionSize

!		end if

!		print *, arg4Size



		! 2. allocate space on device for reduction variable (old value, the new value is computed in redArrayDev)
		allocate ( argument4 ( arg4Size ) )


		



	

		! initialise redArrayHost to 0
!		do i = 1, reductItems !reductionItems = maxblocks
!		
!			redArrayDev(i) = 0.0 ! real(8) variable
!		
!		end do
!
!

		! this to guarantee that the actual reduct value respects user modifications in the main program
		argument4 = c2fPtrArg4


		istat = cudaEventRecord ( stopHostTime, 0 )
		istat = cudaEventSynchronize ( stopHostTime )
		istat = cudaEventElapsedTime ( tmpHostTime, startHostTime, stopHostTime )

		op_par_loop_update%hostTime = 0
		op_par_loop_update%hostTime = op_par_loop_update%hostTime + tmpHostTime
		tmpHostTime = 0

		istat = cudaEventRecord ( startKernelTime, 0 )
		

		call  op_cuda_update <<< nblocks, nthreads, nshared >>> ( argSizes, &
																														&	argument0, &
																														& argument1, &
																														& argument2, &
																														& argument3, &
																														& redArrayDev, &
																														& offsetS, &
																														& set%size, &
																														& warpSizeOP2, &
																														& redStartOffset &
																													& )

		! synchronise threads after kernel call
		threadSynchRet = cudaThreadSynchronize()

		istat = cudaEventRecord ( stopKernelTime, 0 )
		istat = cudaEventSynchronize ( stopKernelTime )
		istat = cudaEventElapsedTime ( op_par_loop_update%kernelTime, startKernelTime, stopKernelTime )

		
		istat = cudaEventRecord ( startHostTime, 0 )

		

		! 2. reduct the host array to the single user variable
		! implements:
		! for (int b=0; b<maxblocks; b++)
    !		for (int d=0; d<1; d++)
		!			arg4h[d] = arg4h[d] + ((double *)arg4.dat)[d+b*1];
		do b = 1, reductItems
		
			do d = 0, 0

				! 1 for argument4 is needed because we map scalar variables to array of 1 position
				! possibly this works always because global data are always scalar values?
				
				! +1 is needed because in this case we are using the Fortran indexing notation (1:N)
				partialArg4Sum = argument4(d+1)
				partialRedArrayDev4Sum = redArrayDev ( d + b * 1 )
				argument4(d+1) = partialArg4Sum + partialRedArrayDev4Sum
				!c2fPtrArg4(d+1) = c2fPtrArg4(d+1) + redArrayHost ( d + b * 1 )
			
			end do
		
		end do

		
		! copy back device to host of global variable
		c2fPtrArg4 = argument4

		istat = cudaEventRecord ( stopHostTime, 0 )
		istat = cudaEventSynchronize ( stopHostTime )
		istat = cudaEventElapsedTime ( tmpHostTime, startHostTime, stopHostTime )

		op_par_loop_update%hostTime = op_par_loop_update%hostTime + tmpHostTime	

		deallocate ( redArrayDev )
		deallocate ( argument4 )
		
	end function op_par_loop_update

	

end module update_cuda_module
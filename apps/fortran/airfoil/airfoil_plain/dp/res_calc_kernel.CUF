!
! auto-generated by op2.py on 2013-06-13 14:57
!

MODULE RES_CALC_MODULE
USE OP2_CONSTANTS
USE OP2_FORTRAN_DECLARATIONS
USE OP2_FORTRAN_RT_SUPPORT
USE ISO_C_BINDING
USE CUDAFOR
USE CUDACONFIGURATIONPARAMS


#ifdef _OPENMP
  USE OMP_LIB
#endif

! res_calcvariable declarations

REAL(kind=4) :: loopTimeHostres_calc
REAL(kind=4) :: loopTimeKernelres_calc
INTEGER(kind=4) :: numberCalledres_calc

TYPE ( c_ptr )  :: planRet_res_calc

CONTAINS

! cpu user function
#include "res_calc.inc"

attributes (device) &
SUBROUTINE res_calc_gpu(x1,x2,q1,q2,adt1,adt2,res1,res2)
  IMPLICIT NONE
  REAL(kind=8), DIMENSION(2) :: x1
  REAL(kind=8), DIMENSION(2), INTENT(IN) :: x2
  REAL(kind=8), DIMENSION(4), INTENT(IN) :: q1
  REAL(kind=8), DIMENSION(4), INTENT(IN) :: q2
  REAL(kind=8), INTENT(IN) :: adt1
  REAL(kind=8), INTENT(IN) :: adt2
  REAL(kind=8), DIMENSION(4) :: res1
  REAL(kind=8), DIMENSION(4) :: res2
  REAL(kind=8) :: dx,dy,mu,ri,p1,vol1,p2,vol2,f

  dx = x1(1) - x2(1)
  dy = x1(2) - x2(2)
  ri = 1.0 / q1(1)
  p1 = gm1_OP2 * (q1(4) - 0.5 * ri * (q1(2) * q1(2) + q1(3) * q1(3)))
  vol1 = ri * (q1(2) * dy - q1(3) * dx)
  ri = 1.0 / q2(1)
  p2 = gm1_OP2 * (q2(4) - 0.5 * ri * (q2(2) * q2(2) + q2(3) * q2(3)))
  vol2 = ri * (q2(2) * dy - q2(3) * dx)
  mu = 0.5 * (adt1 + adt2) * eps_OP2
  f = 0.5 * (vol1 * q1(1) + vol2 * q2(1)) + mu * (q1(1) - q2(1))
  res1(1) = res1(1) + f
  res2(1) = res2(1) - f
  f = 0.5 * (vol1 * q1(2) + p1 * dy + vol2 * q2(2) + p2 * dy) + mu * (q1(2) - q2(2))
  res1(2) = res1(2) + f
  res2(2) = res2(2) - f
  f = 0.5 * (vol1 * q1(3) - p1 * dx + vol2 * q2(3) - p2 * dx) + mu * (q1(3) - q2(3))
  res1(3) = res1(3) + f
  res2(3) = res2(3) - f
  f = 0.5 * (vol1 * (q1(4) + p1) + vol2 * (q2(4) + p2)) + mu * (q1(4) - q2(4))
  res1(4) = res1(4) + f
  res2(4) = res2(4) - f
END SUBROUTINE


! CUDA kernel function
attributes (global) SUBROUTINE op_cuda_res_calc( &
  & opDat1Deviceres_calc, &
  & opMap1Deviceres_calc, &
  & opDat3Deviceres_calc, &
  & opMap3Deviceres_calc, &
  & opDat5Deviceres_calc, &
  & opMap5Deviceres_calc, &
  & opDat7Deviceres_calc, &
  & opMap7Deviceres_calc, &
  & pblkMap, &
  & poffset, &
  & pnelems, &
  & pnthrcol, &
  & pthrcol, &
  & setSize, &
  & blockOffset)

  IMPLICIT NONE

! local variables
  real(8), DEVICE, INTENT(IN) :: opDat1Deviceres_calc(*)
  INTEGER(kind=4), DEVICE :: opMap1Deviceres_calc(*)
  real(8), DEVICE, INTENT(IN) :: opDat3Deviceres_calc(*)
  INTEGER(kind=4), DEVICE :: opMap3Deviceres_calc(*)
  real(8), DEVICE, INTENT(IN) :: opDat5Deviceres_calc(*)
  INTEGER(kind=4), DEVICE :: opMap5Deviceres_calc(*)
  real(8), DEVICE :: opDat7Deviceres_calc(*)
  INTEGER(kind=4), DEVICE :: opMap7Deviceres_calc(*)

  INTEGER(kind=4), DIMENSION(0:*), DEVICE :: pblkMap
  INTEGER(kind=4), DIMENSION(0:*), DEVICE :: poffset
  INTEGER(kind=4), DIMENSION(0:*), DEVICE :: pnelems
  INTEGER(kind=4), DIMENSION(0:*), DEVICE :: pnthrcol
  INTEGER(kind=4), DIMENSION(0:*), DEVICE :: pthrcol
  INTEGER(kind=4), VALUE :: blockOffset
  INTEGER(kind=4), VALUE :: setSize

  real(8), DIMENSION(0:4-1) :: opDat7Local
  real(8), DIMENSION(0:4-1) :: opDat8Local

  INTEGER(kind=4), SHARED :: numOfColours
  INTEGER(kind=4), SHARED :: numberOfActiveThreadsCeiling
  INTEGER(kind=4), SHARED :: blockID
  INTEGER(kind=4), SHARED :: threadBlockOffset
  INTEGER(kind=4), SHARED :: numberOfActiveThreads
  INTEGER(kind=4) :: colour1
  INTEGER(kind=4) :: colour2
  INTEGER(kind=4) :: n1
  INTEGER(kind=4) :: i1
  INTEGER(kind=4) :: i2


  IF (threadIdx%x - 1 .EQ. 0) THEN
    blockID = pblkMap(blockIdx%x - 1 + blockOffset)
    numberOfActiveThreads = pnelems(blockID)
    numberOfActiveThreadsCeiling = blockDim%x * (1 + (numberOfActiveThreads - 1) / blockDim%x)
    numOfColours = pnthrcol(blockID)
    threadBlockOffset = poffset(blockID)

  END IF

  CALL syncthreads()

  i1 = threadIdx%x - 1

  DO WHILE (i1 < numberOfActiveThreadsCeiling )
    colour2 = -1
    IF (i1 < numberOfActiveThreads) THEN
      DO i2 = 0, 4 - 1, 1
        opDat7Local(i2) = 0
      END DO
      DO i2 = 0, 4 - 1, 1
        opDat8Local(i2) = 0
      END DO

! kernel call
      CALL res_calc_gpu( &
      & opDat1Deviceres_calc(1 + opMap1Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 0) * (2):     opMap1Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 0) * (2) + 2), &
      & opDat1Deviceres_calc(1 + opMap1Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 1) * (2):     opMap1Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 1) * (2) + 2), &
      & opDat3Deviceres_calc(1 + opMap3Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 0) * (4):     opMap3Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 0) * (4) + 4), &
      & opDat3Deviceres_calc(1 + opMap3Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 1) * (4):     opMap3Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 1) * (4) + 4), &
      & opDat5Deviceres_calc(1 + opMap5Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 0)), &
      & opDat5Deviceres_calc(1 + opMap5Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 1)), &
      & opDat7Local, &
      & opDat8Local &
      & )

      colour2 = pthrcol(i1 + threadBlockOffset)
    END IF
    DO colour1 = 0, numOfColours - 1, 1
      IF (colour2 .EQ. colour1) THEN
        DO i2 = 0, 4 - 1, 1
          opDat7Deviceres_calc(1 + i2 + opMap7Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 0) * (4)) = &
          & opDat7Deviceres_calc(1 + i2 + opMap7Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 0) * (4)) + opDat7Local(i2)
        END DO

        DO i2 = 0, 4 - 1, 1
          opDat7Deviceres_calc(1 + i2 + opMap7Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 1) * (4)) = &
          & opDat7Deviceres_calc(1 + i2 + opMap7Deviceres_calc(1 + i1 + threadBlockOffset + setSize * 1) * (4)) + opDat8Local(i2)
        END DO

      END IF
      CALL syncthreads()
    END DO
    i1 = i1 + blockDim%x
  END DO



END SUBROUTINE

attributes (host) SUBROUTINE res_calc_host( userSubroutine, set, &
  & opArg1, &
  & opArg2, &
  & opArg3, &
  & opArg4, &
  & opArg5, &
  & opArg6, &
  & opArg7, &
  & opArg8 )

  IMPLICIT NONE
  character(len=8), INTENT(IN) :: userSubroutine
  TYPE ( op_set ) , INTENT(IN) :: set

  TYPE ( op_arg ) , INTENT(IN) :: opArg1
  TYPE ( op_arg ) , INTENT(IN) :: opArg2
  TYPE ( op_arg ) , INTENT(IN) :: opArg3
  TYPE ( op_arg ) , INTENT(IN) :: opArg4
  TYPE ( op_arg ) , INTENT(IN) :: opArg5
  TYPE ( op_arg ) , INTENT(IN) :: opArg6
  TYPE ( op_arg ) , INTENT(IN) :: opArg7
  TYPE ( op_arg ) , INTENT(IN) :: opArg8

  IF (getHybridGPU()) THEN
    CALL res_calc_host_gpu( userSubroutine, set, &
    & opArg1, &
    & opArg2, &
    & opArg3, &
    & opArg4, &
    & opArg5, &
    & opArg6, &
    & opArg7, &
    & opArg8 )
  ELSE
    CALL res_calc_host_cpu( userSubroutine, set, &
    & opArg1, &
    & opArg2, &
    & opArg3, &
    & opArg4, &
    & opArg5, &
    & opArg6, &
    & opArg7, &
    & opArg8 )
  END IF
END SUBROUTINE


! Stub for GPU execution

attributes (host) SUBROUTINE res_calc_host_gpu( userSubroutine, set, &
  & opArg1, &
  & opArg2, &
  & opArg3, &
  & opArg4, &
  & opArg5, &
  & opArg6, &
  & opArg7, &
  & opArg8 )

  IMPLICIT NONE
  character(len=8), INTENT(IN) :: userSubroutine
  TYPE ( op_set ) , INTENT(IN) :: set

  TYPE ( op_arg ) , INTENT(IN) :: opArg1
  TYPE ( op_arg ) , INTENT(IN) :: opArg2
  TYPE ( op_arg ) , INTENT(IN) :: opArg3
  TYPE ( op_arg ) , INTENT(IN) :: opArg4
  TYPE ( op_arg ) , INTENT(IN) :: opArg5
  TYPE ( op_arg ) , INTENT(IN) :: opArg6
  TYPE ( op_arg ) , INTENT(IN) :: opArg7
  TYPE ( op_arg ) , INTENT(IN) :: opArg8

  TYPE ( op_arg ) , DIMENSION(8) :: opArgArray
  INTEGER(kind=4) :: numberOfOpDats
  INTEGER(kind=4) :: n_upper
  INTEGER(kind=4) :: returnSetKernelTiming


  real(8), DIMENSION(:), DEVICE, ALLOCATABLE :: opDat1Deviceres_calc
  INTEGER(kind=4), DIMENSION(:), DEVICE, ALLOCATABLE :: opMap1Deviceres_calc
  real(8), DIMENSION(:), DEVICE, ALLOCATABLE :: opDat3Deviceres_calc
  INTEGER(kind=4), DIMENSION(:), DEVICE, ALLOCATABLE :: opMap3Deviceres_calc
  real(8), DIMENSION(:), DEVICE, ALLOCATABLE :: opDat5Deviceres_calc
  INTEGER(kind=4), DIMENSION(:), DEVICE, ALLOCATABLE :: opMap5Deviceres_calc
  real(8), DIMENSION(:), DEVICE, ALLOCATABLE :: opDat7Deviceres_calc
  INTEGER(kind=4), DIMENSION(:), DEVICE, ALLOCATABLE :: opMap7Deviceres_calc

  INTEGER(kind=4) :: opDat1Cardinality
  INTEGER(kind=4) :: opMap1Cardinality
  INTEGER(kind=4) :: opDat3Cardinality
  INTEGER(kind=4) :: opMap3Cardinality
  INTEGER(kind=4) :: opDat5Cardinality
  INTEGER(kind=4) :: opMap5Cardinality
  INTEGER(kind=4) :: opDat7Cardinality
  INTEGER(kind=4) :: opMap7Cardinality

  TYPE ( op_plan ) , POINTER :: actualPlan_res_calc

  INTEGER(kind=4) :: blocksPerGrid
  INTEGER(kind=4) :: threadsPerBlock
  INTEGER(kind=4) :: dynamicSharedMemorySize
  INTEGER(kind=4) :: threadSynchRet
  INTEGER(kind=4), DIMENSION(1:8) :: opDatArray
  INTEGER(kind=4), DIMENSION(1:8) :: mappingIndicesArray
  INTEGER(kind=4), DIMENSION(1:8) :: mappingArray
  INTEGER(kind=4), DIMENSION(1:8) :: accessDescriptorArray
  INTEGER(kind=4), DIMENSION(1:8) :: indirectionDescriptorArray

  INTEGER(kind=4) :: mappingArray1Size
  INTEGER(kind=4) :: mappingArray3Size
  INTEGER(kind=4) :: mappingArray5Size
  INTEGER(kind=4) :: mappingArray7Size

  INTEGER(kind=4) :: numberOfIndirectOpDats
  INTEGER(kind=4) :: blockOffset
  INTEGER(kind=4) :: pblkMapSize
  INTEGER(kind=4) :: poffsetSize
  INTEGER(kind=4) :: pnelemsSize
  INTEGER(kind=4) :: pnthrcolSize
  INTEGER(kind=4) :: pthrcolSize
  INTEGER(kind=4), POINTER, DIMENSION(:) :: ncolblk
  INTEGER(kind=4), DIMENSION(:), DEVICE, ALLOCATABLE :: pblkMap
  INTEGER(kind=4), DIMENSION(:), DEVICE, ALLOCATABLE :: poffset
  INTEGER(kind=4), DIMENSION(:), DEVICE, ALLOCATABLE :: pnelems
  INTEGER(kind=4), DIMENSION(:), DEVICE, ALLOCATABLE :: pnthrcol
  INTEGER(kind=4), DIMENSION(:), DEVICE, ALLOCATABLE :: pthrcol
  INTEGER(kind=4) :: partitionSize
  INTEGER(kind=4) :: blockSize
  INTEGER(kind=4) :: i1
  INTEGER(kind=4) :: i2
  INTEGER(kind=4), SAVE :: calledTimes

  INTEGER(kind=4) :: istat
  REAL(kind=4) :: accumulatorHostTime
  REAL(kind=4) :: accumulatorKernelTime
  REAL(kind=8) :: KT_double
  TYPE ( cudaEvent )  :: startTimeHost
  TYPE ( cudaEvent )  :: endTimeHost
  TYPE ( cudaEvent )  :: startTimeKernel
  TYPE ( cudaEvent )  :: endTimeKernel

  numberOfOpDats = 8

  opArgArray(1) = opArg1
  opArgArray(2) = opArg2
  opArgArray(3) = opArg3
  opArgArray(4) = opArg4
  opArgArray(5) = opArg5
  opArgArray(6) = opArg6
  opArgArray(7) = opArg7
  opArgArray(8) = opArg8

  n_upper = op_mpi_halo_exchanges_cuda(set%setCPtr,numberOfOpDats,opArgArray)

  istat = cudaEventCreate(startTimeHost)
  istat = cudaEventCreate(endTimeHost)
  istat = cudaEventCreate(startTimeKernel)
  istat = cudaEventCreate(endTimeKernel)

  numberCalledres_calc = numberCalledres_calc + 1
  istat = cudaEventRecord(startTimeHost,0)

  indirectionDescriptorArray(1) = 0
  indirectionDescriptorArray(2) = 0
  indirectionDescriptorArray(3) = 1
  indirectionDescriptorArray(4) = 1
  indirectionDescriptorArray(5) = 2
  indirectionDescriptorArray(6) = 2
  indirectionDescriptorArray(7) = 3
  indirectionDescriptorArray(8) = 3

  numberOfIndirectOpDats = 4

  partitionSize = getPartitionSize(userSubroutine//C_NULL_CHAR,set%setPtr%size)

  planRet_res_calc = FortranPlanCaller( &
  & userSubroutine//C_NULL_CHAR, &
  & set%setCPtr, &
  & partitionSize, &
  & numberOfOpDats, &
  & opArgArray, &
  & numberOfIndirectOpDats, &
  & indirectionDescriptorArray)

  opDat1Cardinality = opArg1%dim * getSetSizeFromOpArg(opArg1)
  opMap1Cardinality = set%setPtr%size * getMapDimFromOpArg(opArg1)
  opDat3Cardinality = opArg3%dim * getSetSizeFromOpArg(opArg3)
  opMap3Cardinality = set%setPtr%size * getMapDimFromOpArg(opArg3)
  opDat5Cardinality = opArg5%dim * getSetSizeFromOpArg(opArg5)
  opMap5Cardinality = set%setPtr%size * getMapDimFromOpArg(opArg5)
  opDat7Cardinality = opArg7%dim * getSetSizeFromOpArg(opArg7)
  opMap7Cardinality = set%setPtr%size * getMapDimFromOpArg(opArg7)


  CALL c_f_pointer(opArg1%data_d,opDat1Deviceres_calc,(/opDat1Cardinality/))
  CALL c_f_pointer(opArg1%map_data_d,opMap1Deviceres_calc,(/opMap1Cardinality/))
  CALL c_f_pointer(opArg3%data_d,opDat3Deviceres_calc,(/opDat3Cardinality/))
  CALL c_f_pointer(opArg3%map_data_d,opMap3Deviceres_calc,(/opMap3Cardinality/))
  CALL c_f_pointer(opArg5%data_d,opDat5Deviceres_calc,(/opDat5Cardinality/))
  CALL c_f_pointer(opArg5%map_data_d,opMap5Deviceres_calc,(/opMap5Cardinality/))
  CALL c_f_pointer(opArg7%data_d,opDat7Deviceres_calc,(/opDat7Cardinality/))
  CALL c_f_pointer(opArg7%map_data_d,opMap7Deviceres_calc,(/opMap7Cardinality/))

  CALL c_f_pointer(planRet_res_calc,actualPlan_res_calc)
  CALL c_f_pointer(actualPlan_res_calc%ncolblk,ncolblk,(/set%setPtr%size/))
  pblkMapSize = actualPlan_res_calc%nblocks
  CALL c_f_pointer(actualPlan_res_calc%blkmap_d,pblkMap,(/pblkMapSize/))
  poffsetSize = actualPlan_res_calc%nblocks
  CALL c_f_pointer(actualPlan_res_calc%offset_d,poffset,(/poffsetSize/))
  pnelemsSize = actualPlan_res_calc%nblocks
  CALL c_f_pointer(actualPlan_res_calc%nelems_d,pnelems,(/pnelemsSize/))
  pnthrcolSize = actualPlan_res_calc%nblocks
  CALL c_f_pointer(actualPlan_res_calc%nthrcol,pnthrcol,(/pnthrcolSize/))
  pthrcolSize = set%setPtr%size
  CALL c_f_pointer(actualPlan_res_calc%thrcol,pthrcol,(/pthrcolSize/))

  istat = cudaEventRecord(endTimeHost,0)
  istat = cudaEventSynchronize(endTimeHost)
  istat = cudaEventElapsedTime(accumulatorHostTime,startTimeHost,endTimeHost)

  loopTimeHostres_calc = loopTimeHostres_calc + accumulatorHostTime
  istat = cudaEventRecord(startTimeKernel,0)

  blockOffset = 0

  threadsPerBlock = getBlockSize(userSubroutine//C_NULL_CHAR,set%setPtr%size)
  DO i2 = 0, actualPlan_res_calc%ncolors - 1, 1
    IF (i2 .EQ. actualPlan_res_calc%ncolors_core) THEN
      CALL op_mpi_wait_all_cuda(numberOfOpDats,opArgArray)
    END IF

    blocksPerGrid = ncolblk(i2 + 1)
    dynamicSharedMemorySize = reductionSize(opArgArray,numberOfOpDats) * threadsPerBlock

    CALL op_cuda_res_calc <<<blocksPerGrid,threadsPerBlock,dynamicSharedMemorySize>>> (&
    & opDat1Deviceres_calc, &
    & opMap1Deviceres_calc, &
    & opDat3Deviceres_calc, &
    & opMap3Deviceres_calc, &
    & opDat5Deviceres_calc, &
    & opMap5Deviceres_calc, &
    & opDat7Deviceres_calc, &
    & opMap7Deviceres_calc, &
    & pblkMap, &
    & poffset,pnelems,pnthrcol,pthrcol,set%setPtr%size+set%setPtr%exec_size, blockOffset)

    blockOffset = blockOffset + blocksPerGrid
  END DO


  IF ((n_upper .EQ. 0) .OR. (n_upper .EQ. set%setPtr%core_size)) THEN
    CALL op_mpi_wait_all_cuda(numberOfOpDats,opArgArray)
  END IF


  istat = cudaEventRecord(endTimeKernel,0)
  istat = cudaEventSynchronize(endTimeKernel)
  istat = cudaEventElapsedTime(accumulatorKernelTime,startTimeKernel,endTimeKernel)
  loopTimeKernelres_calc = loopTimeKernelres_calc + accumulatorKernelTime


  CALL op_mpi_set_dirtybit_cuda(numberOfOpDats,opArgArray)

  KT_double = REAL(accumulatorKernelTime / 1000.00)
  returnSetKernelTiming = setKernelTime(2 , userSubroutine//C_NULL_CHAR, &
  & KT_double, actualPlan_res_calc%transfer,actualPlan_res_calc%transfer2)
  calledTimes = calledTimes + 1
END SUBROUTINE


! Stub for CPU execution

SUBROUTINE res_calc_host_cpu( userSubroutine, set, &
  & opArg1, &
  & opArg2, &
  & opArg3, &
  & opArg4, &
  & opArg5, &
  & opArg6, &
  & opArg7, &
  & opArg8 )

  IMPLICIT NONE
  character(kind=c_char,len=*), INTENT(IN) :: userSubroutine
  type ( op_set ) , INTENT(IN) :: set

  type ( op_arg ) , INTENT(IN) :: opArg1
  type ( op_arg ) , INTENT(IN) :: opArg2
  type ( op_arg ) , INTENT(IN) :: opArg3
  type ( op_arg ) , INTENT(IN) :: opArg4
  type ( op_arg ) , INTENT(IN) :: opArg5
  type ( op_arg ) , INTENT(IN) :: opArg6
  type ( op_arg ) , INTENT(IN) :: opArg7
  type ( op_arg ) , INTENT(IN) :: opArg8

  type ( op_arg ) , DIMENSION(8) :: opArgArray
  INTEGER(kind=4) :: numberOfOpDats
  INTEGER(kind=4) :: n_upper
  type ( op_set_core ) , POINTER :: opSetCore

  INTEGER(kind=4), POINTER, DIMENSION(:) :: opDat1Map
  INTEGER(kind=4) :: opDat1MapDim
  real(8), POINTER, DIMENSION(:) :: opDat1Local
  INTEGER(kind=4) :: opDat1Cardinality

  INTEGER(kind=4), POINTER, DIMENSION(:) :: opDat3Map
  INTEGER(kind=4) :: opDat3MapDim
  real(8), POINTER, DIMENSION(:) :: opDat3Local
  INTEGER(kind=4) :: opDat3Cardinality

  INTEGER(kind=4), POINTER, DIMENSION(:) :: opDat5Map
  INTEGER(kind=4) :: opDat5MapDim
  real(8), POINTER, DIMENSION(:) :: opDat5Local
  INTEGER(kind=4) :: opDat5Cardinality

  INTEGER(kind=4), POINTER, DIMENSION(:) :: opDat7Map
  INTEGER(kind=4) :: opDat7MapDim
  real(8), POINTER, DIMENSION(:) :: opDat7Local
  INTEGER(kind=4) :: opDat7Cardinality

  INTEGER(kind=4) :: threadID
  INTEGER(kind=4) :: numberOfThreads
  INTEGER(kind=4), DIMENSION(1:8) :: timeArrayStart
  INTEGER(kind=4), DIMENSION(1:8) :: timeArrayEnd
  REAL(kind=8) :: startTimeHost
  REAL(kind=8) :: endTimeHost
  REAL(kind=8) :: startTimeKernel
  REAL(kind=8) :: endTimeKernel
  REAL(kind=8) :: accumulatorHostTime
  REAL(kind=8) :: accumulatorKernelTime
  INTEGER(kind=4) :: returnSetKernelTiming
  LOGICAL :: firstTime_res_calc = .TRUE.
  type ( c_ptr )  :: planRet_res_calc
  type ( op_plan ) , POINTER :: actualPlan_res_calc
  INTEGER(kind=4), POINTER, DIMENSION(:) :: ncolblk_res_calc
  INTEGER(kind=4), POINTER, DIMENSION(:) :: blkmap_res_calc
  INTEGER(kind=4), POINTER, DIMENSION(:) :: nelems_res_calc
  INTEGER(kind=4), POINTER, DIMENSION(:) :: offset_res_calc
  INTEGER(kind=4), DIMENSION(1:8) :: indirectionDescriptorArray
  INTEGER(kind=4) :: numberOfIndirectOpDats
  INTEGER(kind=4) :: blockOffset
  INTEGER(kind=4) :: nblocks
  INTEGER(kind=4) :: partitionSize
  INTEGER(kind=4) :: blockID
  INTEGER(kind=4) :: nelem
  INTEGER(kind=4) :: offset_b


  INTEGER(kind=4) :: i1,i2,n

  numberOfOpDats = 8

  opArgArray(1) = opArg1
  opArgArray(2) = opArg2
  opArgArray(3) = opArg3
  opArgArray(4) = opArg4
  opArgArray(5) = opArg5
  opArgArray(6) = opArg6
  opArgArray(7) = opArg7
  opArgArray(8) = opArg8

  n_upper = op_mpi_halo_exchanges(set%setCPtr,numberOfOpDats,opArgArray)
  numberCalledres_calc = numberCalledres_calc+ 1

  call date_and_time(values=timeArrayStart)
  startTimeHost = 1.00000 * timeArrayStart(8) + &
  & 1000.00 * timeArrayStart(7) + &
  & 60000 * timeArrayStart(6) + &
  & 3600000 * timeArrayStart(5)

#ifdef OP_PART_SIZE_1
  partitionSize = OP_PART_SIZE_1
#else
  partitionSize = 0
#endif

#ifdef _OPENMP
  numberOfThreads = omp_get_max_threads()
#else
  numberOfThreads = 1
#endif
    indirectionDescriptorArray(1) = 0
    indirectionDescriptorArray(2) = 0
    indirectionDescriptorArray(3) = 1
    indirectionDescriptorArray(4) = 1
    indirectionDescriptorArray(5) = 2
    indirectionDescriptorArray(6) = 2
    indirectionDescriptorArray(7) = 3
    indirectionDescriptorArray(8) = 3

    numberOfIndirectOpDats = 4

    planRet_res_calc = FortranPlanCaller( &
    & userSubroutine//C_NULL_CHAR, &
    & set%setCPtr, &
    & partitionSize, &
    & numberOfOpDats, &
    & opArgArray, &
    & numberOfIndirectOpDats, &
    & indirectionDescriptorArray)

    CALL c_f_pointer(planRet_res_calc,actualPlan_res_calc)
    CALL c_f_pointer(actualPlan_res_calc%ncolblk,ncolblk_res_calc,(/actualPlan_res_calc%ncolors_core/))
    CALL c_f_pointer(actualPlan_res_calc%blkmap,blkmap_res_calc,(/actualPlan_res_calc%nblocks/))
    CALL c_f_pointer(actualPlan_res_calc%offset,offset_res_calc,(/actualPlan_res_calc%nblocks/))
    CALL c_f_pointer(actualPlan_res_calc%nelems,nelems_res_calc,(/actualPlan_res_calc%nblocks/))

    opSetCore => set%setPtr

    opDat1Cardinality = opArg1%dim * getSetSizeFromOpArg(opArg1)
    opDat1MapDim = getMapDimFromOpArg(opArg1)
    opDat3Cardinality = opArg3%dim * getSetSizeFromOpArg(opArg3)
    opDat3MapDim = getMapDimFromOpArg(opArg3)
    opDat5Cardinality = opArg5%dim * getSetSizeFromOpArg(opArg5)
    opDat5MapDim = getMapDimFromOpArg(opArg5)
    opDat7Cardinality = opArg7%dim * getSetSizeFromOpArg(opArg7)
    opDat7MapDim = getMapDimFromOpArg(opArg7)
    CALL c_f_pointer(opArg1%data,opDat1Local,(/opDat1Cardinality/))
    CALL c_f_pointer(opArg1%map_data,opDat1Map,(/opSetCore%size*opDat1MapDim/))
    CALL c_f_pointer(opArg3%data,opDat3Local,(/opDat3Cardinality/))
    CALL c_f_pointer(opArg3%map_data,opDat3Map,(/opSetCore%size*opDat3MapDim/))
    CALL c_f_pointer(opArg5%data,opDat5Local,(/opDat5Cardinality/))
    CALL c_f_pointer(opArg5%map_data,opDat5Map,(/opSetCore%size*opDat5MapDim/))
    CALL c_f_pointer(opArg7%data,opDat7Local,(/opDat7Cardinality/))
    CALL c_f_pointer(opArg7%map_data,opDat7Map,(/opSetCore%size*opDat7MapDim/))



    call date_and_time(values=timeArrayEnd)
    endTimeHost = 1.00000 * timeArrayEnd(8) + &
    & 1000 * timeArrayEnd(7)  + &
    & 60000 * timeArrayEnd(6) + &
    & 3600000 * timeArrayEnd(5)

    accumulatorHostTime = endTimeHost - startTimeHost
    loopTimeHostres_calc = loopTimeHostres_calc + accumulatorHostTime

    call date_and_time(values=timeArrayStart)
    startTimeKernel = 1.00000 * timeArrayStart(8) + &
    & 1000 * timeArrayStart(7) + &
    & 60000 * timeArrayStart(6) + &
    & 3600000 * timeArrayStart(5)

    blockOffset = 0

    DO i1 = 0, actualPlan_res_calc%ncolors - 1, 1
      IF (i1 .EQ. actualPlan_res_calc%ncolors_core) THEN
        CALL op_mpi_wait_all(numberOfOpDats,opArgArray)
      END IF

      nblocks = ncolblk_res_calc(i1 + 1)
      !$OMP PARALLEL DO private (threadID, blockID, nelem, offset_b)
      DO i2 = 0, nblocks - 1, 1
        threadID = omp_get_thread_num()
        blockID = blkmap_res_calc(i2+blockOffset+1)
        nelem = nelems_res_calc(blockID+1)
        offset_b = offset_res_calc(blockID+1)
        DO n = 0, nelem - 1, 1
! kernel call
        CALL res_calc( &
          & opDat1Local(1 + opDat1Map(1 + (n+offset_b) * opDat1MapDim + 0) * (2) : opDat1Map(1 + (n+offset_b) * opDat1MapDim + 0) * (2) + 2), &
          & opDat1Local(1 + opDat1Map(1 + (n+offset_b) * opDat1MapDim + 1) * (2) : opDat1Map(1 + (n+offset_b) * opDat1MapDim + 1) * (2) + 2), &
          & opDat3Local(1 + opDat3Map(1 + (n+offset_b) * opDat3MapDim + 0) * (4) : opDat3Map(1 + (n+offset_b) * opDat3MapDim + 0) * (4) + 4), &
          & opDat3Local(1 + opDat3Map(1 + (n+offset_b) * opDat3MapDim + 1) * (4) : opDat3Map(1 + (n+offset_b) * opDat3MapDim + 1) * (4) + 4), &
          & opDat5Local(1 + opDat5Map(1 + (n+offset_b) * opDat5MapDim + 0)), &
          & opDat5Local(1 + opDat5Map(1 + (n+offset_b) * opDat5MapDim + 1)), &
          & opDat7Local(1 + opDat7Map(1 + (n+offset_b) * opDat7MapDim + 0) * (4) : opDat7Map(1 + (n+offset_b) * opDat7MapDim + 0) * (4) + 4), &
          & opDat7Local(1 + opDat7Map(1 + (n+offset_b) * opDat7MapDim + 1) * (4) : opDat7Map(1 + (n+offset_b) * opDat7MapDim + 1) * (4) + 4) &
          & )
        END DO
      END DO
      !$OMP END PARALLEL DO
      blockOffset = blockOffset + nblocks
    END DO
    IF ((n_upper .EQ. 0) .OR. (n_upper .EQ. opSetCore%core_size)) THEN
      CALL op_mpi_wait_all(numberOfOpDats,opArgArray)
    END IF


    call date_and_time(values=timeArrayEnd)
    endTimeKernel = 1.00000 * timeArrayEnd(8) + &
    & 1000 * timeArrayEnd(7) + &
    & 60000 * timeArrayEnd(6) + &
    & 3600000 * timeArrayEnd(5)

    accumulatorKernelTime = endTimeKernel - startTimeKernel
    loopTimeKernelres_calc = loopTimeKernelres_calc + accumulatorKernelTime

    call date_and_time(values=timeArrayStart)
    startTimeHost = 1.00000 * timeArrayStart(8) + &
    & 1000.00 * timeArrayStart(7) + &
    & 60000 * timeArrayStart(6) + &
    & 3600000 * timeArrayStart(5)

    CALL op_mpi_set_dirtybit(numberOfOpDats,opArgArray)

    call date_and_time(values=timeArrayEnd)
    endTimeHost = 1.00000 * timeArrayEnd(8) + &
    1000 * timeArrayEnd(7) + &
    60000 * timeArrayEnd(6) + &
    3600000 * timeArrayEnd(5)

    accumulatorHostTime = endTimeHost - startTimeHost
    loopTimeHostres_calc = loopTimeHostres_calc + accumulatorHostTime

    returnSetKernelTiming = setKernelTime(2 , userSubroutine//C_NULL_CHAR, &
    & accumulatorKernelTime / 1000.00,actualPlan_res_calc%transfer,actualPlan_res_calc%transfer2)
  END SUBROUTINE
  END MODULE
